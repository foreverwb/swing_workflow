import json
import time
import base64
import copy
from pathlib import Path
from typing import Dict, Any, List, Optional
from loguru import logger

# ä¿®å¤ 1: æ­£ç¡®å¯¼å…¥ ModelClientManager
from core.model_client import ModelClientManager

import prompts
import schemas
from code_nodes import (
    event_detection_main,
    scoring_main,
    strategy_calc_main,
    comparison_main,
    aggregator_main
)

class WorkflowEngine:
    """å·¥ä½œæµå¼•æ“ï¼ˆæ”¯æŒæ–‡ä»¶å¤¹æ‰«æã€åˆ†æ‰¹è¯†åˆ«ä¸å¢é‡åˆå¹¶ï¼‰"""
    
    def __init__(self, model_client_manager: ModelClientManager, env_vars: Dict[str, Any]):
        self.model_client = model_client_manager
        self.env_vars = env_vars
        
        # ä¼šè¯çŠ¶æ€å˜é‡ (ç”¨äº code_aggregator çš„å¢é‡åˆå¹¶)
        self.conversation_vars = {
            "missing_count": 0,
            "data_status": "initial",
            "current_symbol": "",
            "first_parse_data": ""  # è¿™é‡Œå­˜å‚¨ä¸Šä¸€è½®å®Œæ•´è§£æçš„æ•°æ®å­—ç¬¦ä¸²
        }
        
        logger.info("å·¥ä½œæµå¼•æ“åˆå§‹åŒ–å®Œæˆ")
        
        self.cache_file = Path("data/temp") / "workflow_state.json"
        self.cache_file.parent.mkdir(parents=True, exist_ok=True)
        self._load_state()
    
    def _load_state(self):
        """ä»ç£ç›˜åŠ è½½ä¹‹å‰çš„åˆ†æçŠ¶æ€"""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r') as f:
                    self.conversation_vars = json.load(f)
                logger.info("ğŸ“‚ å·²åŠ è½½ä¹‹å‰çš„åˆ†æçŠ¶æ€ï¼Œæ”¯æŒå¢é‡è¡¥é½")
            except Exception as e:
                logger.warning(f"åŠ è½½çŠ¶æ€å¤±è´¥: {e}")
    
    def _save_state(self):
        """ä¿å­˜å½“å‰çŠ¶æ€åˆ°ç£ç›˜"""
        try:
            with open(self.cache_file, 'w') as f:
                json.dump(self.conversation_vars, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜çŠ¶æ€å¤±è´¥: {e}")
    

    def run(self, symbol: str, data_folder: Path) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´å·¥ä½œæµ
        """
        logger.info(f"ğŸš€ å¼€å§‹å®Œæ•´åˆ†æ {symbol}")
        
        # 1. æ‰«æå›¾ç‰‡
        image_paths = self._scan_folder_images(data_folder)
        if not image_paths:
            return {"status": "error", "message": f"æ–‡ä»¶å¤¹ {data_folder} ä¸­æœªæ‰¾åˆ°å›¾ç‰‡"}
            
        logger.info(f"ğŸ“Š æ‰«æåˆ° {len(image_paths)} å¼ å›¾ç‰‡ï¼Œå‡†å¤‡è¿›è¡Œåˆ†æ‰¹è§†è§‰åˆ†æ")
        
        # 2. Agent 3 æ•°æ®æ ¡éªŒ (åˆ†æ‰¹æ‰§è¡Œ + å†…éƒ¨åˆå¹¶)
        # è¿”å›çš„æ˜¯å½“å‰æ–‡ä»¶å¤¹å†…æ‰€æœ‰å›¾ç‰‡è§£æåçš„èšåˆç»“æœ
        current_run_data = self._run_agent3_validate(symbol, image_paths)
        
        # 3. è°ƒç”¨ Aggregator (å¤„ç†è·¨è½®æ¬¡çš„æ•°æ®ç´¯ç§¯)
        # å°†"å½“å‰æ–‡ä»¶å¤¹è§£æç»“æœ"ä¸"å†å²ç¼“å­˜æ•°æ®"è¿›è¡Œåˆå¹¶
        aggregated_result = self._run_code_aggregator(current_run_data, symbol)
        
        # è§£æèšåˆåçš„ç»“æœ
        final_data = self._safe_parse_json(aggregated_result.get("result"))
        data_status = aggregated_result.get("data_status")
        
        # 4. æ ¹æ®çŠ¶æ€å†³å®šåç»­æµç¨‹
        if data_status == "awaiting_data":
            logger.warning(f"âš ï¸ æ•°æ®ä»ç¼ºå¤± {aggregated_result.get('missing_count')} ä¸ªå­—æ®µï¼Œç”Ÿæˆè¡¥é½æŒ‡å¼•")
            return {
                "status": "incomplete",
                # ç›´æ¥è¿”å› Aggregator ç”Ÿæˆçš„ç»“æ„åŒ–æŒ‡å¼•
                "guide": self._format_è¡¥é½æŒ‡å¼•(aggregated_result),
                "missing_count": aggregated_result.get("missing_count"),
                "merge_history": final_data.get("_merge_history", [])
            }
            
        elif data_status == "ready":
            logger.info("âœ… æ•°æ®å®Œæ•´ï¼Œå¼€å§‹åç»­åˆ†ææµç¨‹")
            # å°†å®Œæ•´çš„ targets æ•°æ®ä¼ å…¥åç»­ Agent
            return self._run_analysis_pipeline(final_data)
            
        else:
            return {"status": "error", "message": f"æœªçŸ¥çš„æ•°æ®çŠ¶æ€: {data_status}"}

    def _scan_folder_images(self, folder: Path) -> List[Path]:
        """æ‰«ææ–‡ä»¶å¤¹è·å–æ‰€æœ‰æ”¯æŒçš„å›¾ç‰‡"""
        extensions = ['*.png', '*.PNG', '*.jpg', '*.JPG', '*.jpeg', '*.JPEG']
        image_paths = []
        for ext in extensions:
            image_paths.extend(list(folder.glob(ext)))
        return sorted(image_paths)

    def _encode_image_to_base64(self, image_path: Path) -> Optional[str]:
        """æœ¬åœ°å›¾ç‰‡è½¬ Base64"""
        try:
            with open(image_path, "rb") as image_file:
                base64_str = base64.b64encode(image_file.read()).decode('utf-8')
                ext = image_path.suffix.lower()
                mime_type = "image/jpeg" if ext in ['.jpg', '.jpeg'] else "image/png"
                return f"data:{mime_type};base64,{base64_str}"
        except Exception as e:
            logger.error(f"âŒ å›¾ç‰‡ç¼–ç å¤±è´¥ {image_path.name}: {e}")
            return None

    def _run_agent3_validate(self, symbol: str, image_paths: List[Path]) -> Dict:
        """
        Agent 3 æ ¸å¿ƒé€»è¾‘ï¼šåˆ†æ‰¹å¤„ç† -> è§£æ JSON -> å†…éƒ¨åˆå¹¶
        """
        BATCH_SIZE = 3  # æ¯æ‰¹ 3 å¼ å›¾ï¼Œé¿å… Payload è¿‡å¤§
        SLEEP_SECONDS = 2 # å†·å´æ—¶é—´
        
        # è¿™æ˜¯ä¸€ä¸ªç©ºçš„ç»“æ„ï¼Œç”¨äºç´¯ç§¯å½“å‰æ–‡ä»¶å¤¹å†…æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœ
        combined_batch_result = {}
        
        total_images = len(image_paths)
        total_batches = (total_images + BATCH_SIZE - 1) // BATCH_SIZE
        
        logger.info(f"ğŸ“¦ å›¾ç‰‡æ€»æ•° {total_images}ï¼Œå°†åˆ†ä¸º {total_batches} ä¸ªæ‰¹æ¬¡å¤„ç†")

        for i in range(0, total_images, BATCH_SIZE):
            batch_index = (i // BATCH_SIZE) + 1
            batch_paths = image_paths[i : i + BATCH_SIZE]
            
            logger.info(f"ğŸ”„ [Agent3] å¤„ç†ç¬¬ {batch_index}/{total_batches} æ‰¹æ¬¡ ({len(batch_paths)} å¼ å›¾)...")
            
            # 1. æ„å»º Prompt
            system_content = prompts.agent3_validate.get_system_prompt(self.env_vars)
            system_content += f"\n\n[é‡è¦æç¤º] è¿™æ˜¯ä»»åŠ¡çš„åˆ†æ‰¹è¾“å…¥ï¼ˆç¬¬ {batch_index}/{total_batches} æ‰¹ï¼‰ã€‚è¯·æå–å¯è§æ•°æ®ã€‚è‹¥æ•°æ®ä¸åœ¨å½“å‰å›¾ç‰‡ä¸­ï¼Œè¯·ä¿æŒå­—æ®µä¸ºç©ºæˆ–é»˜è®¤å€¼ï¼Œä¸è¦ç¼–é€ ã€‚"

            # ä¿®å¤å‚æ•°é”™è¯¯ï¼šget_user_prompt åªæ¥å— symbol å’Œ file_list
            user_prompt = prompts.agent3_validate.get_user_prompt(
                symbol, 
                [p.name for p in batch_paths] 
            )

            inputs = [
                {"role": "system", "content": system_content},
                {"role": "user", "content": user_prompt}
            ]
            
            # 2. å›¾ç‰‡è½¬ Base64
            valid_img_count = 0
            for path in batch_paths:
                b64_str = self._encode_image_to_base64(path)
                if b64_str:
                    inputs.append({
                        "role": "user",
                        "content": [{"type": "image_url", "image_url": {"url": b64_str}}]
                    })
                    valid_img_count += 1
            
            if valid_img_count == 0:
                logger.warning(f"âš ï¸ ç¬¬ {batch_index} æ‰¹æ¬¡æ— æœ‰æ•ˆå›¾ç‰‡ï¼Œè·³è¿‡")
                continue

            # 3. è°ƒç”¨ API
            try:
                response = self.model_client.responses_create(
                    inputs=inputs,
                    agent_name="agent3",
                    json_schema=schemas.agent3_schema.get_schema()
                )
                
                # 4. å¢å¼ºçš„ JSON è§£æé€»è¾‘ (ä¿®å¤æ ¼å¼å¼‚å¸¸è­¦å‘Š)
                raw_content = response.get("content", {})
                batch_data = {}
                
                if isinstance(raw_content, dict):
                    batch_data = raw_content
                elif isinstance(raw_content, str):
                    try:
                        # æ¸…æ´— Markdown æ ‡è®°
                        clean_text = raw_content.strip()
                        if clean_text.startswith("```json"):
                            clean_text = clean_text[7:]
                        if clean_text.startswith("```"):
                            clean_text = clean_text[3:]
                        if clean_text.endswith("```"):
                            clean_text = clean_text[:-3]
                        batch_data = json.loads(clean_text.strip())
                    except json.JSONDecodeError:
                        logger.error(f"âŒ ç¬¬ {batch_index} æ‰¹æ¬¡ JSON è§£æå¤±è´¥")
                        logger.debug(f"åŸå§‹å†…å®¹ç‰‡æ®µ: {raw_content[:200]}")
                        continue # è·³è¿‡æ­¤æ‰¹æ¬¡åˆå¹¶

                # 5. æ‰§è¡Œå•æ¬¡è¿è¡Œå†…çš„åˆå¹¶ (Intra-run merge)
                if batch_data:
                    self._deep_merge(combined_batch_result, batch_data)
                    logger.success(f"âœ… ç¬¬ {batch_index} æ‰¹æ¬¡æ•°æ®åˆå¹¶æˆåŠŸ")
                
                # å†·å´
                if batch_index < total_batches:
                    time.sleep(SLEEP_SECONDS)
                    
            except Exception as e:
                logger.error(f"âŒ ç¬¬ {batch_index} æ‰¹æ¬¡è°ƒç”¨å¤±è´¥: {e}")
                continue

        return combined_batch_result

    def _run_code_aggregator(self, current_run_data: Dict, symbol: str) -> Dict:
        """è°ƒç”¨ Aggregator èŠ‚ç‚¹è¿›è¡Œè·¨è½®æ¬¡æ•°æ®ç´¯ç§¯"""
        result = aggregator_main(
            agent3_output=current_run_data,
            first_parse_data=self.conversation_vars["first_parse_data"], # ä¼ å…¥å†å²ç¼“å­˜
            current_symbol=symbol,
            data_status=self.conversation_vars["data_status"],
            missing_count=self.conversation_vars["missing_count"],
            **self.env_vars
        )
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€ (å®ç°è®°å¿†åŠŸèƒ½)
        if "first_parse_data" in result:
            self.conversation_vars["first_parse_data"] = result["first_parse_data"]
        if "data_status" in result:
            self.conversation_vars["data_status"] = result["data_status"]
        if "missing_count" in result:
            self.conversation_vars["missing_count"] = result["missing_count"]
        
        self._save_state()
        return result

    def _deep_merge(self, target: Dict, source: Dict):
        """
        é€’å½’åˆå¹¶å­—å…¸ï¼šä»…å½“ Source åŒ…å«æœ‰æ•ˆæ•°æ®æ—¶è¦†ç›– Target
        æœ‰æ•ˆæ•°æ®å®šä¹‰ï¼šé -999, é "N/A", éç©º, é "false"
        """
        invalid_values = [-999, "N/A", "false", "False", "æ•°æ®ä¸è¶³", "", None]
        
        for key, value in source.items():
            if isinstance(value, dict):
                if key not in target:
                    target[key] = {}
                self._deep_merge(target[key], value)
            else:
                # é€»è¾‘ï¼š
                # 1. Target æ²¡æœ‰ -> å¡«å…¥
                # 2. Target æ˜¯æ— æ•ˆå€¼ ä¸” Source æ˜¯æœ‰æ•ˆå€¼ -> è¦†ç›–
                if key not in target:
                    target[key] = value
                elif (target[key] in invalid_values) and (value not in invalid_values):
                    target[key] = value

    def _format_è¡¥é½æŒ‡å¼•(self, result: Dict) -> str:
        """æ ¼å¼åŒ– Aggregator è¿”å›çš„æŒ‡å¼•ä¿¡æ¯"""
        return f"""
==================================================
ğŸ“‹ æ•°æ®è¡¥é½æŒ‡å¼• ({result.get('user_guide_progress', '0%')})
==================================================

{result.get('user_guide_summary', '')}

ğŸ”´ å¿…é¡»è¡¥é½ (Critical):
{result.get('user_guide_priority_critical', 'æ— ')}

ğŸŸ  å»ºè®®è¡¥é½ (High):
{result.get('user_guide_priority_high', 'æ— ')}

ğŸŸ¡ å¯é€‰è¡¥é½ (Medium):
{result.get('user_guide_priority_medium', 'æ— ')}

ğŸ“ å†å²åˆå¹¶è®°å½•:
{result.get('user_guide_merge_log', '')}

ğŸ‘‰ ä¸‹ä¸€æ­¥: {result.get('user_guide_next_action', '')}
"""

    def _run_analysis_pipeline(self, aggregated_result: Dict) -> Dict:
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        
        # è§£æèšåˆæ•°æ®
        merged_data = self._safe_parse_json(aggregated_result.get("result"))
        
        # Step 1: CODE1 äº‹ä»¶æ£€æµ‹
        logger.info("ğŸ” Step 1: äº‹ä»¶æ£€æµ‹")
        event_result = event_detection_main(
            user_query=f"åˆ†æ {merged_data.get('symbol', 'UNKNOWN')}",
            **self.env_vars
        )
        
        # Step 2: CODE2 è¯„åˆ†è®¡ç®—
        logger.info("ğŸ“Š Step 2: å››ç»´è¯„åˆ†")
        scoring_result = scoring_main(
            agent3_output=merged_data,
            technical_score=merged_data.get("technical_analysis", {}).get("ta_score", 0),
            **self.env_vars
        )
        
        scoring_data = self._safe_parse_json(scoring_result.get("result"))
        
        # Step 3: Agent 5 åœºæ™¯åˆ†æ
        logger.info("ğŸ¯ Step 3: åœºæ™¯æ¨æ¼”")
        agent5_result = self._run_agent5_scenario(scoring_data)
        
        # Step 4: CODE3 ç­–ç•¥è¾…åŠ©è®¡ç®—
        logger.info("ğŸ§® Step 4: ç­–ç•¥è¾…åŠ©")
        strategy_calc_result = strategy_calc_main(
            agent3_output=merged_data,
            agent5_output=agent5_result["content"],
            technical_score=merged_data.get("technical_analysis", {}).get("ta_score", 0),
            **self.env_vars
        )
        
        strategy_calc_data = self._safe_parse_json(strategy_calc_result.get("result"))
        
        # Step 5: Agent 6 ç­–ç•¥ç”Ÿæˆ
        logger.info("ğŸ’¡ Step 5: ç­–ç•¥ç”Ÿæˆ")
        agent6_result = self._run_agent6_strategy(
            agent5_result, 
            strategy_calc_data,
            merged_data
        )
        
        # Step 6: CODE4 ç­–ç•¥å¯¹æ¯”
        logger.info("âš–ï¸ Step 6: ç­–ç•¥å¯¹æ¯”")
        comparison_result = comparison_main(
            strategies_output=agent6_result["content"],
            scenario_output=agent5_result["content"],
            agent3_output=merged_data,
            **self.env_vars
        )
        
        comparison_data = self._safe_parse_json(comparison_result.get("result"))
        
        # Step 7: Agent 7 ç­–ç•¥æ’åº
        logger.info("ğŸ† Step 7: ç­–ç•¥æ’åº")
        agent7_result = self._run_agent7_comparison(
            comparison_data,
            agent5_result["content"],
            agent6_result["content"]
        )
        
        # Step 8: Agent 8 æœ€ç»ˆæŠ¥å‘Š
        logger.info("ğŸ“‹ Step 8: ç”ŸæˆæŠ¥å‘Š")
        final_report = self._run_agent8_report(
            merged_data,
            agent5_result["content"],
            agent7_result["content"],
            event_result
        )
        
        logger.success("âœ… åˆ†æå®Œæˆ!")
        
        return {
            "status": "success",
            "report": final_report["content"],
            "event_risk": self._safe_parse_json(event_result.get("result")),
            "scoring": scoring_data,
            "scenario": agent5_result["content"],
            "strategies": agent6_result["content"],
            "ranking": agent7_result["content"]
        }

    def _run_agent2_cmdlist(self, symbol: str) -> Dict:
        """Agent 2: å‘½ä»¤æ¸…å•ç”Ÿæˆ"""
        messages = [
            {
                "role": "system",
                "content": prompts.agent2_cmdlist.get_system_prompt(self.env_vars)
            },
            {
                "role": "user",
                "content": prompts.agent2_cmdlist.get_user_prompt(symbol)
            }
        ]
        
        response = self.model_client.chat_completion(
            messages=messages,
            agent_name="agent2"
        )
        
        return response

    def _run_agent5_scenario(self, scoring_data: Dict) -> Dict:
        """Agent 5: åœºæ™¯åˆ†æ"""
        messages = [
            {
                "role": "system",
                "content": prompts.agent5_scenario.get_system_prompt()
            },
            {
                "role": "user",
                "content": prompts.agent5_scenario.get_user_prompt(scoring_data)
            }
        ]
        
        response = self.model_client.chat_completion(
            messages=messages,
            agent_name="agent5",
            json_schema=schemas.agent5_schema.get_schema()
        )
        
        return response

    def _run_agent6_strategy(self, agent5_result: Dict, calc_data: Dict, agent3_data: Dict) -> Dict:
        """Agent 6: ç­–ç•¥ç”Ÿæˆ"""
        messages = [
            {
                "role": "system",
                "content": prompts.agent6_strategy.get_system_prompt(self.env_vars)
            },
            {
                "role": "user",
                "content": prompts.agent6_strategy.get_user_prompt(
                    agent5_result, 
                    calc_data,
                    agent3_data
                )
            }
        ]
        
        response = self.model_client.chat_completion(
            messages=messages,
            agent_name="agent6",
            json_schema=schemas.agent6_schema.get_schema()
        )
        
        return response

    def _run_agent7_comparison(self, comparison_data: Dict, scenario: Dict, strategies: Dict) -> Dict:
        """Agent 7: ç­–ç•¥å¯¹æ¯”"""
        messages = [
            {
                "role": "system",
                "content": prompts.agent7_comparison.get_system_prompt()
            },
            {
                "role": "user",
                "content": prompts.agent7_comparison.get_user_prompt(
                    comparison_data, scenario, strategies
                )
            }
        ]
        
        response = self.model_client.chat_completion(
            messages=messages,
            agent_name="agent7",
            json_schema=schemas.agent7_schema.get_schema()
        )
        
        return response

    def _run_agent8_report(self, agent3: Dict, agent5: Dict, agent7: Dict, event: Dict) -> Dict:
        """Agent 8: æœ€ç»ˆæŠ¥å‘Š"""
        messages = [
            {
                "role": "system",
                "content": prompts.agent8_report.get_system_prompt()
            },
            {
                "role": "user",
                "content": prompts.agent8_report.get_user_prompt(
                    agent3, agent5, agent7, event
                )
            }
        ]
        
        response = self.model_client.chat_completion(
            messages=messages,
            agent_name="agent8"
        )
        
        return response

    def _safe_parse_json(self, data: Any) -> Dict:
        """å®‰å…¨è§£æJSON"""
        if isinstance(data, dict):
            return data
        elif isinstance(data, str):
            try:
                return json.loads(data)
            except json.JSONDecodeError as e:
                logger.error(f"JSONè§£æå¤±è´¥: {str(e)[:100]}")
                logger.debug(f"åŸå§‹æ•°æ®: {data[:200]}")
                return {}
        else:
            logger.warning(f"æœªçŸ¥æ•°æ®ç±»å‹: {type(data)}")
            return {}