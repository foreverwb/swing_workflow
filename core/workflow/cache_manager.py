"""
ç¼“å­˜ç®¡ç†å™¨ï¼ˆé‡æ„ç‰ˆï¼‰
èŒè´£ï¼š
1. ç®¡ç†å®Œæ•´åˆ†æç»“æœç¼“å­˜
2. ç®¡ç†å¸Œè…Šå€¼å¿«ç…§ï¼ˆæ”¯æŒå¤šæ¬¡ refreshï¼‰
3. å¿«ç…§å¯¹æ¯”åŠŸèƒ½
"""

import json
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime
from loguru import logger
import re


class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨ï¼ˆé‡æ„ç‰ˆï¼‰"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨"""
        # å®Œæ•´åˆ†æè¾“å‡ºç›®å½•
        self.output_dir = Path("data/output")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¸´æ—¶ç¼“å­˜ç›®å½•
        self.temp_dir = Path("data/temp")
        self.temp_dir.mkdir(parents=True, exist_ok=True)
    
    # ============================================
    # å®Œæ•´åˆ†æç»“æœç¼“å­˜
    # ============================================
    
    def _get_output_filename(self, symbol: str, start_date: str = None) -> Path:
        """
        è·å–è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        æ ¼å¼ï¼šdata/output/{SYMBOL}/{SYMBOL}_{start_date}.json
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: åˆ†æå¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDï¼‰ï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨ä»Šå¤©
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if not start_date:
            start_date = datetime.now().strftime("%Y%m%d")
        
        symbol_dir = self.output_dir / symbol
        symbol_dir.mkdir(parents=True, exist_ok=True)
        
        return symbol_dir / f"{symbol}_{start_date}.json"
    
    def get_cache_file(self, symbol: str, start_date: str = None) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„ï¼ˆå‘åå…¼å®¹ï¼‰"""
        return self._get_output_filename(symbol, start_date)
    
    def load_analysis(self, symbol: str, start_date: str = None) -> Optional[Dict[str, Any]]:
        """
        åŠ è½½å®Œæ•´åˆ†æç»“æœ
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: åˆ†æå¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDï¼‰ï¼Œä¸æŒ‡å®šåˆ™æŸ¥æ‰¾æœ€æ–°
            
        Returns:
            ç¼“å­˜æ•°æ®æˆ– None
        """
        if start_date:
            # åŠ è½½æŒ‡å®šæ—¥æœŸçš„åˆ†æ
            cache_file = self._get_output_filename(symbol, start_date)
        else:
            # æŸ¥æ‰¾æœ€æ–°çš„åˆ†ææ–‡ä»¶
            symbol_dir = self.output_dir / symbol
            if not symbol_dir.exists():
                return None
            
            analysis_files = sorted(symbol_dir.glob(f"{symbol}_*.json"), reverse=True)
            if not analysis_files:
                return None
            
            cache_file = analysis_files[0]
        
        if not cache_file.exists():
            return None
        
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
            return None
    
    def save_complete_analysis(
        self,
        symbol: str,
        initial_data: Dict,
        scenario: Dict,
        strategies: Dict,
        ranking: Dict,
        report: str,
        start_date: str = None,
        cache_file: str = None  # â­ æ–°å¢ï¼šæ”¯æŒæŒ‡å®šç¼“å­˜æ–‡ä»¶
    ):
        """
        ä¿å­˜å®Œæ•´åˆ†æç»“æœåˆ° source_target
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            initial_data: åˆå§‹æ•°æ®ï¼ˆè®¡ç®—åçš„å®Œæ•´æ•°æ®ï¼‰
            scenario: åœºæ™¯åˆ†æ
            strategies: ç­–ç•¥åˆ—è¡¨
            ranking: ç­–ç•¥æ’åº
            report: æœ€ç»ˆæŠ¥å‘Š
            start_date: åˆ†æå¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDï¼‰
            cache_file: æŒ‡å®šç¼“å­˜æ–‡ä»¶åï¼ˆå¦‚ NVDA_20251127.jsonï¼‰
        """
        if not start_date:
            start_date = datetime.now().strftime("%Y%m%d")
        
        # â­ æ”¯æŒæŒ‡å®šç¼“å­˜æ–‡ä»¶
        if cache_file:
            # ä»æ–‡ä»¶åæå– start_date
            match = re.match(r'(\w+)_(\d{8})\.json', cache_file)
            if match:
                start_date = match.group(2)
            cache_path = self.output_dir / symbol / cache_file
        else:
            cache_path = self._get_output_filename(symbol, start_date)
        
        # åŠ è½½ç°æœ‰ç¼“å­˜
        if cache_path.exists():
            with open(cache_path, 'r', encoding='utf-8') as f:
                cached = json.load(f)
        else:
            # åˆ›å»ºæ–°ç¼“å­˜
            cached = {
                "symbol": symbol,
                "start_date": datetime.strptime(start_date, "%Y%m%d").strftime("%Y-%m-%d"),
                "created_at": datetime.now().isoformat()
            }
        
        # â­ å†™å…¥ source_targetï¼ˆè®¡ç®—åçš„å®Œæ•´æ•°æ® + scenarioï¼‰
        cached["source_target"] = {
            "timestamp": datetime.now().isoformat(),
            "data": initial_data,  # åŒ…å« 23ä¸ªåŸå§‹å­—æ®µ + 3ä¸ªè®¡ç®—å­—æ®µ
            "scenario": scenario,
            "strategies": strategies,
            "ranking": ranking,
            "report": report
        }
        
        cached["last_updated"] = datetime.now().isoformat()
        
        # ä¿å­˜ç¼“å­˜
        cache_path.parent.mkdir(parents=True, exist_ok=True)
        self._save_cache(cache_path, cached)
        logger.success(f"âœ… å®Œæ•´åˆ†æç»“æœå·²ä¿å­˜: {cache_path}")
    
    def add_backtest_record(self, symbol: str, record: Dict[str, Any], start_date: str = None):
        """
        æ·»åŠ å›æµ‹è®°å½•
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            record: å›æµ‹è®°å½•
            start_date: åˆ†æå¼€å§‹æ—¥æœŸ
        """
        cached = self.load_analysis(symbol, start_date)
        
        if not cached:
            logger.warning(f"æœªæ‰¾åˆ° {symbol} çš„ç¼“å­˜ï¼Œæ— æ³•æ·»åŠ å›æµ‹è®°å½•")
            return
        
        if "backtest_records" not in cached:
            cached["backtest_records"] = []
        
        record["timestamp"] = datetime.now().isoformat()
        cached["backtest_records"].append(record)
        
        cache_file = self._get_output_filename(symbol, cached.get("start_date"))
        self._save_cache(cache_file, cached)
        logger.info(f"âœ… å›æµ‹è®°å½•å·²æ·»åŠ ")
    
    # ============================================
    # å¸Œè…Šå€¼å¿«ç…§ç®¡ç†ï¼ˆrefresh å¿«ç…§ï¼‰
    # ============================================
    
    def save_greeks_snapshot(
        self,
        symbol: str,
        data: Dict,
        note: str = "",
        is_initial: bool = False,
        cache_file_name: str = None
    ) -> Dict:
        """
        ä¿å­˜å¸Œè…Šå€¼å¿«ç…§ï¼ˆæ”¯æŒå¤šæ¬¡ refreshï¼‰
        
        æ•°æ®æ ¼å¼ï¼š
        {
            "start_date": "2025-11-27",
            "source_target": {...},  # æœ€åˆçš„å®Œæ•´æ•°æ®
            "snapshots_1": {...},    # ç¬¬1æ¬¡ refresh
            "snapshots_2": {...},    # ç¬¬2æ¬¡ refresh
            ...
        }
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data: å®Œæ•´æ•°æ®
            note: å¤‡æ³¨
            is_initial: æ˜¯å¦ä¸ºåˆå§‹åˆ†æï¼ˆsource_targetï¼‰
            cache_file_name: ç¼“å­˜æ–‡ä»¶åï¼ˆå¦‚ NVDA_20251127.jsonï¼‰
            
        Returns:
            ä¿å­˜ç»“æœ
        """
        # ç¡®å®šå¿«ç…§æ–‡ä»¶è·¯å¾„
        if cache_file_name:
            # ä½¿ç”¨æŒ‡å®šçš„ç¼“å­˜æ–‡ä»¶å
            snapshot_file = self._get_output_filename(
                symbol, 
                cache_file_name.replace(f"{symbol}_", "").replace(".json", "")
            )
        else:
            # ä½¿ç”¨å½“å‰æ—¥æœŸ
            snapshot_file = self._get_output_filename(symbol)
        
        # æå– targets æ•°æ®
        targets = data.get("targets", {})
        
        # åˆ›å»ºå¿«ç…§è®°å½•
        snapshot_record = {
            "timestamp": datetime.now().isoformat(),
            "note": note,
            "targets": targets
        }
        
        # è¯»å–ç°æœ‰å¿«ç…§æ–‡ä»¶
        if snapshot_file.exists():
            with open(snapshot_file, 'r', encoding='utf-8') as f:
                snapshots_data = json.load(f)
        else:
            # é¦–æ¬¡åˆ›å»º
            snapshots_data = {
                "symbol": symbol,
                "start_date": datetime.now().strftime("%Y-%m-%d"),
                "source_target": None
            }
        
        if is_initial:
            # ä¿å­˜åˆå§‹æ•°æ®åˆ° source_target
            snapshots_data["source_target"] = snapshot_record
            logger.info(f"âœ… ä¿å­˜åˆå§‹åˆ†ææ•°æ®åˆ° source_target")
        else:
            # è®¡ç®— refresh æ¬¡æ•°
            snapshot_count = sum(1 for key in snapshots_data.keys() if key.startswith("snapshots_"))
            next_snapshot_key = f"snapshots_{snapshot_count + 1}"
            
            snapshots_data[next_snapshot_key] = snapshot_record
            logger.info(f"âœ… ä¿å­˜ç¬¬ {snapshot_count + 1} æ¬¡ refresh å¿«ç…§")
        
        # ä¿å­˜æ–‡ä»¶
        with open(snapshot_file, 'w', encoding='utf-8') as f:
            json.dump(snapshots_data, f, ensure_ascii=False, indent=2)
        
        logger.success(f"ğŸ’¾ å¿«ç…§å·²ä¿å­˜: {snapshot_file}")
        
        return {
            "status": "success",
            "snapshot_file": str(snapshot_file),
            "snapshot": snapshot_record,
            "total_snapshots": sum(1 for k in snapshots_data.keys() if k.startswith("snapshots_"))
        }
    
    def load_latest_greeks_snapshot(self, symbol: str) -> Optional[Dict]:
        """
        åŠ è½½æœ€æ–°çš„å¸Œè…Šå€¼å¿«ç…§
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            
        Returns:
            æœ€æ–°å¿«ç…§æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        snapshot_file = self._get_snapshot_filename(symbol)
        
        if not snapshot_file.exists():
            logger.warning(f"æœªæ‰¾åˆ°å¿«ç…§æ–‡ä»¶: {snapshot_file}")
            return None
        
        with open(snapshot_file, 'r', encoding='utf-8') as f:
            snapshots_data = json.load(f)
        
        # è·å–æœ€æ–°çš„å¿«ç…§
        snapshot_keys = [k for k in snapshots_data.keys() if k.startswith("snapshots_")]
        
        if not snapshot_keys:
            # å¦‚æœæ²¡æœ‰ refresh å¿«ç…§ï¼Œè¿”å› source_target
            return snapshots_data.get("source_target")
        
        # è¿”å›æœ€åä¸€ä¸ªå¿«ç…§
        latest_key = sorted(snapshot_keys, key=lambda x: int(x.split("_")[1]))[-1]
        return snapshots_data[latest_key]
    
    def get_all_snapshots(self, symbol: str) -> Optional[Dict]:
        """
        è·å–æ‰€æœ‰å¿«ç…§æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            
        Returns:
            å®Œæ•´çš„å¿«ç…§æ–‡ä»¶å†…å®¹
        """
        snapshot_file = self._get_snapshot_filename(symbol)
        
        if not snapshot_file.exists():
            return None
        
        with open(snapshot_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    # ============================================
    # å¿«ç…§å¯¹æ¯”åŠŸèƒ½
    # ============================================
    
    def compare_snapshots(self, symbol: str, from_num: int, to_num: int) -> Optional[Dict]:
        """
        å¯¹æ¯”ä¸¤ä¸ªå¿«ç…§çš„å·®å¼‚
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            from_num: èµ·å§‹å¿«ç…§ç¼–å·ï¼ˆ0 è¡¨ç¤º source_targetï¼‰
            to_num: ç»“æŸå¿«ç…§ç¼–å·
            
        Returns:
            å¯¹æ¯”ç»“æœå­—å…¸
        """
        snapshots_data = self.get_all_snapshots(symbol)
        
        if not snapshots_data:
            logger.warning(f"æœªæ‰¾åˆ° {symbol} çš„å¿«ç…§æ•°æ®")
            return None
        
        # è·å–èµ·å§‹å¿«ç…§
        if from_num == 0:
            from_snapshot = snapshots_data.get("source_target")
            from_label = "source_target"
        else:
            from_key = f"snapshots_{from_num}"
            from_snapshot = snapshots_data.get(from_key)
            from_label = f"å¿«ç…§ #{from_num}"
        
        # è·å–ç»“æŸå¿«ç…§
        to_key = f"snapshots_{to_num}"
        to_snapshot = snapshots_data.get(to_key)
        to_label = f"å¿«ç…§ #{to_num}"
        
        if not from_snapshot or not to_snapshot:
            logger.warning(f"å¿«ç…§ä¸å­˜åœ¨: {from_label} æˆ– {to_label}")
            return None
        
        # æå– targets æ•°æ®
        from_targets = from_snapshot.get("targets", {})
        to_targets = to_snapshot.get("targets", {})
        
        # å¯¹æ¯”å…³é”®å­—æ®µ
        changes = {}
        
        # 1. spot_price
        from_price = from_targets.get("spot_price")
        to_price = to_targets.get("spot_price")
        if from_price and to_price and from_price != to_price:
            change_pct = ((to_price - from_price) / from_price) * 100
            changes["spot_price"] = {
                "from": from_price,
                "to": to_price,
                "change": round(to_price - from_price, 2),
                "change_pct": round(change_pct, 2)
            }
        
        # 2. gamma_metrics
        from_gamma = from_targets.get("gamma_metrics", {})
        to_gamma = to_targets.get("gamma_metrics", {})
        
        for field in ["net_gex", "vol_trigger", "gap_distance_dollar"]:
            from_val = from_gamma.get(field)
            to_val = to_gamma.get(field)
            if from_val and to_val and from_val != to_val:
                change_pct = ((to_val - from_val) / from_val) * 100 if from_val != 0 else 0
                changes[f"gamma_metrics.{field}"] = {
                    "from": from_val,
                    "to": to_val,
                    "change": round(to_val - from_val, 2),
                    "change_pct": round(change_pct, 2)
                }
        
        # spot_vs_trigger å˜åŒ–ï¼ˆå­—ç¬¦ä¸²ï¼‰
        from_trigger = from_gamma.get("spot_vs_trigger")
        to_trigger = to_gamma.get("spot_vs_trigger")
        if from_trigger != to_trigger:
            changes["gamma_metrics.spot_vs_trigger"] = {
                "from": from_trigger,
                "to": to_trigger,
                "changed": True
            }
        
        # 3. walls
        from_walls = from_targets.get("walls", {})
        to_walls = to_targets.get("walls", {})
        
        for field in ["call_wall", "put_wall", "major_wall"]:
            from_val = from_walls.get(field)
            to_val = to_walls.get(field)
            if from_val and to_val and from_val != to_val:
                change_pct = ((to_val - from_val) / from_val) * 100 if from_val != 0 else 0
                changes[f"walls.{field}"] = {
                    "from": from_val,
                    "to": to_val,
                    "change": round(to_val - from_val, 2),
                    "change_pct": round(change_pct, 2)
                }
        
        # 4. atm_iv
        from_iv = from_targets.get("atm_iv", {})
        to_iv = to_targets.get("atm_iv", {})
        
        for field in ["iv_7d", "iv_14d"]:
            from_val = from_iv.get(field)
            to_val = to_iv.get(field)
            if from_val and to_val and from_val != to_val:
                change_pct = ((to_val - from_val) / from_val) * 100 if from_val != 0 else 0
                changes[f"atm_iv.{field}"] = {
                    "from": from_val,
                    "to": to_val,
                    "change": round(to_val - from_val, 2),
                    "change_pct": round(change_pct, 2)
                }
        
        return {
            "from_snapshot": {
                "label": from_label,
                "timestamp": from_snapshot.get("timestamp"),
                "note": from_snapshot.get("note")
            },
            "to_snapshot": {
                "label": to_label,
                "timestamp": to_snapshot.get("timestamp"),
                "note": to_snapshot.get("note")
            },
            "changes": changes,
            "total_changes": len(changes)
        }
    
    # ============================================
    # è¾…åŠ©æ–¹æ³•
    # ============================================
    
    def _save_cache(self, cache_file: Path, data: Dict[str, Any]):
        """ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶"""
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    @staticmethod
    def _get_nested_value(data: Dict, path: str):
        """è·å–åµŒå¥—å­—æ®µå€¼ï¼ˆæ”¯æŒç‚¹å·è·¯å¾„ï¼‰"""
        keys = path.split('.')
        value = data
        for key in keys:
            if isinstance(value, dict):
                value = value.get(key)
            else:
                return None
        return value if value != -999 else None