"""
åˆ†ææµç¨‹ç¼–æ’å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰
é›†æˆç¾åŒ–æ§åˆ¶å°è¾“å‡º
"""

import json
from typing import Dict, Any
from loguru import logger

import prompts
import schemas
from code_nodes import (
    event_detection_main,
    scoring_main,
    strategy_calc_main,
    comparison_main
)
from utils.console_printer import (
    print_header,
    print_step,
    print_success,
    print_error,
    print_info,
    print_warning
)


class AnalysisPipeline:
    """åˆ†ææµç¨‹ç¼–æ’å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    
    def __init__(
        self, agent_executor, 
        cache_manager, 
        env_vars: Dict[str, Any],
        enable_pretty_print: bool = True,
        cache_file: str = None
    ):
        """
        åˆå§‹åŒ– Pipeline
        
        Args:
            agent_executor: Agent æ‰§è¡Œå™¨
            cache_manager: ç¼“å­˜ç®¡ç†å™¨
            env_vars: ç¯å¢ƒå˜é‡
            enable_pretty_print: æ˜¯å¦å¯ç”¨ç¾åŒ–æ‰“å°
        """
        self.agent_executor = agent_executor
        self.cache_manager = cache_manager
        self.env_vars = env_vars
        self.enable_pretty_print = enable_pretty_print
        self.cache_file = cache_file  # â­ æ–°å¢ï¼šæ”¯æŒæŒ‡å®šç¼“å­˜æ–‡ä»¶
    
    def run(self, initial_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´æµç¨‹ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Args:
            initial_data: åˆå§‹æ•°æ®ï¼ˆåŒ…å« 23 ä¸ªå­—æ®µï¼‰
            
        Returns:
            å®Œæ•´åˆ†æç»“æœ
        """
        # æ‰“å°æµç¨‹æ ‡é¢˜
        if self.enable_pretty_print:
            symbol = initial_data.get("symbol", "UNKNOWN")
            print_header(
                f"æœŸæƒç­–ç•¥åˆ†ææµç¨‹",
                f"æ ‡çš„: {symbol} | å®Œæ•´åˆ†ææ¨¡å¼"
            )
        
        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
        context = {
            "initial_data": initial_data,
            "symbol": initial_data.get("symbol", "UNKNOWN"),
            "calculated_data": initial_data
        }
        
        # å®šä¹‰æµç¨‹æ­¥éª¤
        steps = [
            ("äº‹ä»¶æ£€æµ‹", self._step_event_detection, "æ£€æµ‹è´¢æŠ¥ã€FOMC ç­‰é‡å¤§äº‹ä»¶"),
            ("è¯„åˆ†è®¡ç®—", self._step_scoring, "è®¡ç®—å››ç»´è¯„åˆ†ï¼ˆGamma/Wall/Direction/IVï¼‰"),
            ("åœºæ™¯åˆ†æ", self._step_scenario, "æ¨æ¼”å¸‚åœºåœºæ™¯åŠæ¦‚ç‡"),
            ("ç­–ç•¥è¾…åŠ©", self._step_strategy_calc, "è®¡ç®—è¡Œæƒä»·ã€DTEã€RRã€Pw"),
            ("ç­–ç•¥ç”Ÿæˆ", self._step_strategy, "ä¸ºæ¯ä¸ªåœºæ™¯è®¾è®¡æœŸæƒç­–ç•¥"),
            ("ç­–ç•¥å¯¹æ¯”", self._step_comparison, "è®¡ç®—ç­–ç•¥ EVã€RARã€æµåŠ¨æ€§"),
            ("ç­–ç•¥æ’åº", self._step_ranking, "ç»¼åˆè¯„åˆ†å¹¶æ’åºæ¨è"),
            ("ç”ŸæˆæŠ¥å‘Š", self._step_report, "ç”Ÿæˆäººç±»å¯è¯»çš„åˆ†ææŠ¥å‘Š"),
            ("ä¿å­˜ç»“æœ", self._step_save_results, "ä¿å­˜åˆ†æç»“æœåˆ°ç¼“å­˜")
        ]
        
        # æ‰§è¡Œæµç¨‹
        for i, (step_name, step_func, step_desc) in enumerate(steps, 1):
            if self.enable_pretty_print:
                print_step(i, len(steps), f"{step_name} - {step_desc}")
            
            logger.info(f"ğŸ“ Step {i}/{len(steps)}: {step_name}")
            
            try:
                context = step_func(context)
                
                if self.enable_pretty_print:
                    print_success(f"{step_name} å®Œæˆ")
            
            except Exception as e:
                if self.enable_pretty_print:
                    print_error(f"{step_name} å¤±è´¥", str(e))
                
                logger.error(f"âŒ Step {step_name} å¤±è´¥: {str(e)}")
                
                return {
                    "status": "error",
                    "failed_step": step_name,
                    "error": str(e)
                }
        
        # æµç¨‹å®Œæˆ
        if self.enable_pretty_print:
            print_success("ğŸ‰ å®Œæ•´åˆ†ææµç¨‹å®Œæˆï¼")
        
        return {
            "status": "success",
            "report": context.get("final_report"),
            "event_risk": context.get("event_result"),
            "scoring": context.get("scoring_data"),
            "scenario": context.get("scenario_result"),
            "strategies": context.get("strategies_result"),
            "ranking": context.get("ranking_result")
        }
    
    def _step_event_detection(self, context: Dict) -> Dict:
        """æ­¥éª¤1ï¼šäº‹ä»¶æ£€æµ‹"""
        result = self.agent_executor.execute_code_node(
            node_name="äº‹ä»¶æ£€æµ‹",
            func=event_detection_main,
            description="æ£€æµ‹è´¢æŠ¥ã€FOMCã€OPEX ç­‰äº‹ä»¶",
            user_query=f"åˆ†æ {context['symbol']}",
            **self.env_vars
        )
        
        context["event_result"] = self._safe_parse_json(result)
        return context
    
    def _step_scoring(self, context: Dict) -> Dict:
        """æ­¥éª¤2ï¼šè¯„åˆ†è®¡ç®—"""
        calculated_data = context["calculated_data"]
        
        ta_score = calculated_data.get("technical_analysis", {}).get("ta_score", 0)
        
        result = self.agent_executor.execute_code_node(
            node_name="è¯„åˆ†è®¡ç®—",
            func=scoring_main,
            description="è®¡ç®— Gamma Regimeã€ç ´å¢™ã€æ–¹å‘ã€IV å››ç»´è¯„åˆ†",
            agent3_output=calculated_data,
            technical_score=ta_score,
            **self.env_vars
        )
        
        context["scoring_data"] = self._safe_parse_json(result)
        return context
    
    def _step_scenario(self, context: Dict) -> Dict:
        """æ­¥éª¤3ï¼šåœºæ™¯åˆ†æ"""
        scoring_data = context["scoring_data"]
        
        messages = [
            {
                "role": "system",
                "content": prompts.agent5_scenario.get_system_prompt()
            },
            {
                "role": "user",
                "content": prompts.agent5_scenario.get_user_prompt(scoring_data)
            }
        ]
        
        response = self.agent_executor.execute_agent(
            agent_name="agent5",
            messages=messages,
            json_schema=schemas.agent5_schema.get_schema(),
            description="åŸºäºè¯„åˆ†æ¨æ¼” 3-5 ç§å¸‚åœºåœºæ™¯"
        )
        
        context["scenario_result"] = response.get("content", {})
        return context
    
    def _step_strategy_calc(self, context: Dict) -> Dict:
        """æ­¥éª¤4ï¼šç­–ç•¥è¾…åŠ©è®¡ç®—"""
        calculated_data = context["calculated_data"]
        scenario_result = context["scenario_result"]
        
        ta_score = calculated_data.get("technical_analysis", {}).get("ta_score", 0)
        targets = calculated_data.get("targets", {})
        result = self.agent_executor.execute_code_node(
            node_name="ç­–ç•¥è¾…åŠ©",
            func=strategy_calc_main,
            description="è®¡ç®—è¡Œæƒä»·ã€DTEã€RRã€Pw ç­‰ç­–ç•¥å‚æ•°",
            agent3_output=targets,
            agent5_output=scenario_result,
            technical_score=ta_score,
            **self.env_vars
        )
        
        context["strategy_calc_data"] = self._safe_parse_json(result)
        return context
    
    def _step_strategy(self, context: Dict) -> Dict:
        """æ­¥éª¤5ï¼šç­–ç•¥ç”Ÿæˆ"""
        scenario_result = context["scenario_result"]
        strategy_calc_data = context["strategy_calc_data"]
        calculated_data = context["calculated_data"]
        
        messages = [
            {
                "role": "system",
                "content": prompts.agent6_strategy.get_system_prompt(self.env_vars)
            },
            {
                "role": "user",
                "content": prompts.agent6_strategy.get_user_prompt(
                    {"content": scenario_result},
                    strategy_calc_data,
                    calculated_data
                )
            }
        ]
        
        response = self.agent_executor.execute_agent(
            agent_name="agent6",
            messages=messages,
            json_schema=schemas.agent6_schema.get_schema(),
            description="ä¸ºæ¯ä¸ªåœºæ™¯è®¾è®¡ 2-3 ç§æœŸæƒç­–ç•¥"
        )
        print("ç­–ç•¥ç”Ÿæˆ response", response)
        context["strategies_result"] = response.get("content", {})
        return context
    
    def _step_comparison(self, context: Dict) -> Dict:
        """æ­¥éª¤6ï¼šç­–ç•¥å¯¹æ¯”"""
        strategies_result = context["strategies_result"]
        scenario_result = context["scenario_result"]
        calculated_data = context["calculated_data"]
        
        result = self.agent_executor.execute_code_node(
            node_name="ç­–ç•¥å¯¹æ¯”",
            func=comparison_main,
            description="è®¡ç®—ç­–ç•¥ EVã€RARã€æµåŠ¨æ€§ã€åœºæ™¯åŒ¹é…åº¦",
            strategies_output=strategies_result,
            scenario_output=scenario_result,
            agent3_output=calculated_data,
            **self.env_vars
        )
        
        context["comparison_data"] = self._safe_parse_json(result)
        return context
    
    def _step_ranking(self, context: Dict) -> Dict:
        """æ­¥éª¤7ï¼šç­–ç•¥æ’åº"""
        comparison_data = context["comparison_data"]
        scenario_result = context["scenario_result"]
        strategies_result = context["strategies_result"]
        
        messages = [
            {
                "role": "system",
                "content": prompts.agent7_comparison.get_system_prompt()
            },
            {
                "role": "user",
                "content": prompts.agent7_comparison.get_user_prompt(
                    comparison_data,
                    scenario_result,
                    strategies_result
                )
            }
        ]
        
        response = self.agent_executor.execute_agent(
            agent_name="agent7",
            messages=messages,
            json_schema=schemas.agent7_schema.get_schema(),
            description="ç»¼åˆè¯„åˆ†å¹¶æ’åºï¼Œæ¨è Top 3 ç­–ç•¥"
        )
        
        context["ranking_result"] = response.get("content", {})
        return context
    
    def _step_report(self, context: Dict) -> Dict:
        """æ­¥éª¤8ï¼šç”ŸæˆæŠ¥å‘Š"""
        calculated_data = context["calculated_data"]
        scenario_result = context["scenario_result"]
        ranking_result = context["ranking_result"]
        event_result = context["event_result"]
        
        messages = [
            {
                "role": "system",
                "content": prompts.agent8_report.get_system_prompt()
            },
            {
                "role": "user",
                "content": prompts.agent8_report.get_user_prompt(
                    calculated_data,
                    scenario_result,
                    ranking_result,
                    {"result": json.dumps(event_result, ensure_ascii=False)}
                )
            }
        ]
        
        response = self.agent_executor.execute_agent(
            agent_name="agent8",
            messages=messages,
            description="ç”Ÿæˆäººç±»å¯è¯»çš„ Markdown æŠ¥å‘Š"
        )
        
        context["final_report"] = response.get("content", "")
        return context
    
    def _step_save_results(self, context: Dict) -> Dict:
        """æ­¥éª¤9ï¼šä¿å­˜ç»“æœ"""
        symbol = context["symbol"]
        
        self.cache_manager.save_complete_analysis(
            symbol=symbol,
            initial_data=context["calculated_data"],
            scenario=context["scenario_result"],
            strategies=context["strategies_result"],
            ranking=context["ranking_result"],
            report=context["final_report"],
            cache_file=getattr(self, 'cache_file', None)  # â­ ä¼ é€’ cache_file
        )
        
        if self.enable_pretty_print:
            print_info(f"åˆ†æç»“æœå·²ä¿å­˜è‡³ç¼“å­˜: {symbol}")
        
        logger.success(f"âœ… åˆ†æç»“æœå·²ä¿å­˜è‡³ç¼“å­˜: {symbol}")
        
        return context
    
    @staticmethod
    def _safe_parse_json(data: Any) -> Dict:
        """å®‰å…¨è§£æ JSON"""
        if isinstance(data, dict):
            return data
        elif isinstance(data, str):
            try:
                return json.loads(data)
            except:
                return {}
        return {}