"""
Agent3 å¤„ç†å™¨ - æ–°å¢è°ƒè¯•ä¸æ•°æ®è§„èŒƒåŒ–æ¨¡å—
è´Ÿè´£ï¼š
1. Agent3 è¯·æ±‚/å“åº”çš„è¯¦ç»†æ—¥å¿—è®°å½•
2. æ•°æ®ç»“æ„è§„èŒƒåŒ–ï¼ˆä¿®å¤å¸¸è§æ ¼å¼é—®é¢˜ï¼‰
3. å¯¹æ¯”åŸå§‹å“åº”ä¸è§„èŒƒåŒ–åæ•°æ®
"""

import json
from typing import Dict, Any
from loguru import logger


class Agent3Handler:
    """Agent3 å¢å¼ºå¤„ç†å™¨"""
    
    def __init__(self):
        self.debug_mode = True  # è°ƒè¯•æ¨¡å¼å¼€å…³
    
    def log_request(self, symbol: str, inputs: list, image_count: int):
        """
        è®°å½• Agent3 è¯·æ±‚è¯¦æƒ…
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            inputs: è¾“å…¥æ¶ˆæ¯åˆ—è¡¨
            image_count: å›¾ç‰‡æ•°é‡
        """
        if not self.debug_mode:
            return
        
        logger.info("="*80)
        logger.info(f"ğŸ“¤ Agent3 è¯·æ±‚è¯¦æƒ…")
        logger.info("="*80)
        logger.info(f"ğŸ¯ æ ‡çš„: {symbol}")
        logger.info(f"ğŸ“¸ å›¾ç‰‡æ•°é‡: {image_count}")
        logger.info(f"ğŸ“‹ æ¶ˆæ¯æ•°é‡: {len(inputs)}")
    
    def log_response(self, symbol: str, response: Dict, parsed_data: Dict):
        """
        è®°å½• Agent3 å“åº”è¯¦æƒ…
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            response: åŸå§‹å“åº”
            parsed_data: è§£æåçš„æ•°æ®
        """
        if not self.debug_mode:
            return
        
        logger.info("="*80)
        logger.info(f"ğŸ“¥ Agent3 å“åº”è¯¦æƒ…")
        logger.info("="*80)
        logger.info(f"ğŸ¯ æ ‡çš„: {symbol}")
        logger.info(f"ğŸ¤– æ¨¡å‹: {response.get('model', 'Unknown')}")
        
        usage = response.get("usage", {})
        logger.info(f"ğŸ“Š Token ä½¿ç”¨:")
        logger.info(f"  â€¢ è¾“å…¥: {usage.get('input_tokens', 0)}")
        logger.info(f"  â€¢ è¾“å‡º: {usage.get('output_tokens', 0)}")
        
        # æ‰“å°æ•°æ®ç»“æ„æ‘˜è¦
        if "targets" in parsed_data:
            targets = parsed_data["targets"]
            logger.info(f"\nğŸ“‹ æ•°æ®ç»“æ„:")
            logger.info(f"  â€¢ targets ç±»å‹: {type(targets).__name__}")
            
            if isinstance(targets, dict):
                logger.info(f"  â€¢ symbol: {targets.get('symbol', 'N/A')}")
                logger.info(f"  â€¢ status: {targets.get('status', 'N/A')}")
                logger.info(f"  â€¢ spot_price: {targets.get('spot_price', 'N/A')}")
                
                # æ£€æŸ¥åµŒå¥—å­—æ®µ
                if "gamma_metrics" in targets:
                    logger.info(f"  â€¢ gamma_metrics: âœ… å­˜åœ¨")
                if "walls" in targets:
                    logger.info(f"  â€¢ walls: âœ… å­˜åœ¨")
                if "atm_iv" in targets:
                    logger.info(f"  â€¢ atm_iv: âœ… å­˜åœ¨")
            else:
                logger.warning(f"  âš ï¸ targets ä¸æ˜¯å­—å…¸ç±»å‹")
        
        logger.info("="*80 + "\n")
    
    def normalize_structure(self, data: Dict) -> Dict:
        """
        è§„èŒƒåŒ–æ•°æ®ç»“æ„ï¼ˆä¿®å¤å¸¸è§é—®é¢˜ï¼‰
        
        å¸¸è§é—®é¢˜ï¼š
        1. targets æ˜¯ç©ºåˆ—è¡¨ [] è€Œéå­—å…¸
        2. å­—æ®µå¹³é“ºåœ¨æ ¹èŠ‚ç‚¹è€ŒéåµŒå¥—
        3. å­—æ®µåå¤§å°å†™ä¸ä¸€è‡´
        
        Args:
            data: åŸå§‹æ•°æ®
            
        Returns:
            è§„èŒƒåŒ–åçš„æ•°æ®
        """
        normalized = data.copy()
        
        # é—®é¢˜1: targets ä¸ºç©ºåˆ—è¡¨
        if isinstance(normalized.get("targets"), list):
            if not normalized["targets"]:
                logger.warning("âš ï¸ targets æ˜¯ç©ºåˆ—è¡¨ï¼Œè½¬æ¢ä¸ºå­—å…¸")
                normalized["targets"] = {
                    "symbol": "UNKNOWN",
                    "status": "missing_data",
                    "spot_price": -999,
                    "em1_dollar": -999,
                    "walls": {},
                    "gamma_metrics": {},
                    "directional_metrics": {},
                    "atm_iv": {}
                }
            else:
                logger.warning("âš ï¸ targets æ˜¯éç©ºåˆ—è¡¨ï¼Œæå–ç¬¬ä¸€ä¸ªå…ƒç´ ")
                normalized["targets"] = normalized["targets"][0]
        
        # é—®é¢˜2: targets ç¼ºå¤±ï¼Œä½†æœ‰å…¶ä»–å­—æ®µ
        if "targets" not in normalized:
            logger.warning("âš ï¸ targets å­—æ®µç¼ºå¤±ï¼Œå°è¯•ä»æ ¹èŠ‚ç‚¹é‡å»º")
            normalized["targets"] = self._rebuild_targets_from_root(normalized)
        
        # é—®é¢˜3: æ£€æŸ¥å¿…éœ€çš„åµŒå¥—å­—æ®µ
        targets = normalized.get("targets", {})
        if isinstance(targets, dict):
            if "gamma_metrics" not in targets:
                logger.warning("âš ï¸ gamma_metrics ç¼ºå¤±ï¼Œåˆå§‹åŒ–ç©ºå­—å…¸")
                targets["gamma_metrics"] = {}
            if "walls" not in targets:
                logger.warning("âš ï¸ walls ç¼ºå¤±ï¼Œåˆå§‹åŒ–ç©ºå­—å…¸")
                targets["walls"] = {}
            if "atm_iv" not in targets:
                logger.warning("âš ï¸ atm_iv ç¼ºå¤±ï¼Œåˆå§‹åŒ–ç©ºå­—å…¸")
                targets["atm_iv"] = {}
            if "directional_metrics" not in targets:
                logger.warning("âš ï¸ directional_metrics ç¼ºå¤±ï¼Œåˆå§‹åŒ–ç©ºå­—å…¸")
                targets["directional_metrics"] = {}
        
        return normalized
    
    def _rebuild_targets_from_root(self, data: Dict) -> Dict:
        """ä»æ ¹èŠ‚ç‚¹é‡å»º targets å­—å…¸"""
        targets = {
            "symbol": data.get("symbol", "UNKNOWN"),
            "status": data.get("status", "missing_data"),
            "spot_price": data.get("spot_price", -999),
            "em1_dollar": -999,  # â­ è®¡ç®—å­—æ®µè®¾ä¸º -999
            "walls": {},
            "gamma_metrics": {},
            "directional_metrics": {},
            "atm_iv": {}
        }
        
        # å°è¯•ä»æ ¹èŠ‚ç‚¹æå–å¢™ä½
        if "call_wall" in data:
            targets["walls"]["call_wall"] = data["call_wall"]
        if "put_wall" in data:
            targets["walls"]["put_wall"] = data["put_wall"]
        
        # å°è¯•æå– gamma æŒ‡æ ‡
        if "vol_trigger" in data:
            targets["gamma_metrics"]["vol_trigger"] = data["vol_trigger"]
        if "net_gex" in data:
            targets["gamma_metrics"]["net_gex"] = data["net_gex"]
        
        return targets
    
    def print_detailed_comparison(self, original: Dict, normalized: Dict):
        """
        æ‰“å°åŸå§‹æ•°æ®ä¸è§„èŒƒåŒ–åæ•°æ®çš„å¯¹æ¯”
        
        Args:
            original: åŸå§‹æ•°æ®
            normalized: è§„èŒƒåŒ–åçš„æ•°æ®
        """
        if not self.debug_mode:
            return
        
        logger.info("="*80)
        logger.info("ğŸ” æ•°æ®å¯¹æ¯”åˆ†æ")
        logger.info("="*80)
        
        # å¯¹æ¯” targets ç»“æ„
        orig_targets = original.get("targets")
        norm_targets = normalized.get("targets")
        
        logger.info(f"\nğŸ“Š targets å­—æ®µå¯¹æ¯”:")
        logger.info(f"  â€¢ åŸå§‹ç±»å‹: {type(orig_targets).__name__}")
        logger.info(f"  â€¢ è§„èŒƒç±»å‹: {type(norm_targets).__name__}")
        
        if isinstance(orig_targets, list):
            logger.warning(f"  âš ï¸ åŸå§‹æ•°æ® targets æ˜¯åˆ—è¡¨ï¼ˆé•¿åº¦: {len(orig_targets)}ï¼‰")
        
        if isinstance(norm_targets, dict):
            logger.success(f"  âœ… è§„èŒƒåŒ–å targets æ˜¯å­—å…¸ï¼ˆå­—æ®µæ•°: {len(norm_targets)}ï¼‰")
            
            # æ£€æŸ¥åµŒå¥—å­—æ®µå®Œæ•´æ€§
            nested_fields = ["gamma_metrics", "walls", "directional_metrics", "atm_iv"]
            for field in nested_fields:
                orig_has = field in orig_targets if isinstance(orig_targets, dict) else False
                norm_has = field in norm_targets
                
                if not orig_has and norm_has:
                    logger.info(f"  ğŸ”§ {field}: å·²è¡¥å…¨")
                elif orig_has and norm_has:
                    logger.success(f"  âœ… {field}: ä¿æŒä¸å˜")
                else:
                    logger.warning(f"  âš ï¸ {field}: ä»ç¼ºå¤±")
        
        # å¯¹æ¯”å­—æ®µæ•°é‡
        orig_field_count = self._count_fields(original)
        norm_field_count = self._count_fields(normalized)
        
        logger.info(f"\nğŸ“ˆ å­—æ®µç»Ÿè®¡:")
        logger.info(f"  â€¢ åŸå§‹å­—æ®µæ•°: {orig_field_count}")
        logger.info(f"  â€¢ è§„èŒƒå­—æ®µæ•°: {norm_field_count}")
        logger.info(f"  â€¢ å˜åŒ–: {norm_field_count - orig_field_count:+d}")
        
        logger.info("="*80 + "\n")
    
    def _count_fields(self, data: Dict, prefix: str = "") -> int:
        """é€’å½’ç»Ÿè®¡å­—æ®µæ•°é‡"""
        count = 0
        for key, value in data.items():
            count += 1
            if isinstance(value, dict):
                count += self._count_fields(value, f"{prefix}{key}.")
        return count