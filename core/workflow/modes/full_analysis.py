"""
å®Œæ•´åˆ†ææ¨¡å¼
æ‰§è¡Œå®Œæ•´çš„æœŸæƒåˆ†ææµç¨‹
"""
import json
from pathlib import Path
from typing import Dict, Any, List
from loguru import logger

import prompts
import schemas
from code_nodes import aggregator_main, calculator_main
from .base import BaseMode
from ..pipeline import AnalysisPipeline
from core.error_handler import ErrorHandler, WorkflowError, ErrorCategory, ErrorSeverity

class FullAnalysisMode(BaseMode):
    """å®Œæ•´åˆ†ææ¨¡å¼"""
    def execute(
        self, 
        symbol: str, 
        data_folder: Path, 
        state: Dict[str, Any],
        market_params: Dict = None,
        dyn_params: Dict = None       
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´åˆ†æ - å¢å¼ºå®¹é”™"""
        logger.info(f"ğŸ¯ [å®Œæ•´åˆ†ææ¨¡å¼] å¼€å§‹åˆ†æ {symbol}")
        
        # åˆ›å»ºé”™è¯¯å¤„ç†å™¨
        error_handler = ErrorHandler(symbol)
        # ä¿å­˜å¸‚åœºå‚æ•°åˆ°å®ä¾‹ï¼ˆä¾›åç»­ä½¿ç”¨ï¼‰
        self.market_params = market_params or {}
        self.dyn_params = dyn_params or {}
        
        try:
            # 1. æ‰«æå›¾ç‰‡
            error_handler.add_completed_step("æ‰«æå›¾ç‰‡")
            images = self.scan_images(data_folder)
            
            if not images:
                return {
                    "status": "error",
                    "message": f"æ–‡ä»¶å¤¹ {data_folder} ä¸­æœªæ‰¾åˆ°å›¾ç‰‡"
                }
            
            logger.info(f"ğŸ“Š æ‰«æåˆ° {len(images)} å¼ å›¾ç‰‡")
            
            # 2. Agent3 æ•°æ®æ ¡éªŒ
            error_handler.add_completed_step("å¼€å§‹ Agent3")
            agent3_result = self._run_agent3(symbol, images)
            error_handler.add_completed_step("å®Œæˆ Agent3")
            
            # Agent3 ç‰¹æ®Šåˆ¤æ–­ï¼šåŒºåˆ†"æ•°æ®ä¸å®Œæ•´"å’Œ"è¿è¡Œé”™è¯¯"
            content = agent3_result.get("content", {})
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºåˆ—è¡¨ï¼ˆå¸¸è§é”™è¯¯ï¼‰
            if isinstance(content.get("targets"), list) and not content["targets"]:
                raise WorkflowError(
                    message="Agent3 è¿”å›ç©ºåˆ—è¡¨ï¼Œè¿™æ˜¯ä»£ç  Bug æˆ– Schema é—®é¢˜",
                    severity=ErrorSeverity.CRITICAL,
                    category=ErrorCategory.CODE_BUG,
                    node_name="Agent3",
                    context={"response": agent3_result}
                )
            
            # 3. æ•°æ®èšåˆ
            error_handler.add_completed_step("å¼€å§‹ Aggregator")
            aggregated_result = self._run_aggregator(agent3_result, symbol)
            error_handler.add_completed_step("å®Œæˆ Aggregator")
            
            # 4. å­—æ®µè®¡ç®— & éªŒè¯
            error_handler.add_completed_step("å¼€å§‹ Calculator")
            calculated_result = self._run_calculator(aggregated_result, symbol)
            error_handler.add_completed_step("å®Œæˆ Calculator")
            
            # 5. è§£æç»“æœ
            data_status = calculated_result.get("data_status")
            
            # 6. åˆ¤æ–­çŠ¶æ€
            if data_status == "awaiting_data":
                logger.warning(f"âš ï¸ æ•°æ®ç¼ºå¤±ï¼Œç”Ÿæˆè¡¥é½æŒ‡å¼•ï¼ˆéé”™è¯¯ï¼‰")
                return {
                    "status": "incomplete",
                    "guide": calculated_result.get("guide", ""),
                    "validation": calculated_result.get("validation", {}),
                    "raw_result": calculated_result
                }
            
            elif data_status == "ready":
                logger.info("âœ… æ•°æ®å®Œæ•´ï¼Œå¼€å§‹å®Œæ•´åˆ†ææµç¨‹")
                error_handler.add_completed_step("æ•°æ®éªŒè¯é€šè¿‡ï¼Œè¿›å…¥ Pipeline")
                return self._run_full_pipeline(
                    calculated_result, 
                    error_handler,
                    market_params=self.market_params,
                    dyn_params=self.dyn_params
                )
            
            else:
                raise WorkflowError(
                    message=f"æœªçŸ¥çš„æ•°æ®çŠ¶æ€: {data_status}",
                    severity=ErrorSeverity.CRITICAL,
                    category=ErrorCategory.CODE_BUG,
                    node_name="Calculator",
                    context={"data_status": data_status}
                )
    
        except WorkflowError as we:
            # â­ æ•è·åˆ†ç±»åçš„é”™è¯¯
            logger.error(f"âŒ æµç¨‹ç»ˆæ­¢: {we.message}")
            return error_handler.handle_error(we)
        
        except Exception as e:
            # â­ æœªåˆ†ç±»çš„é”™è¯¯ï¼ˆå…œåº•ï¼‰
            logger.exception("âŒ æœªçŸ¥é”™è¯¯")
            workflow_error = WorkflowError(
                message=f"æœªé¢„æœŸçš„é”™è¯¯: {str(e)}",
                severity=ErrorSeverity.CRITICAL,
                category=ErrorCategory.CODE_BUG,
                node_name="Unknown",
                original_error=e
            )
        return error_handler.handle_error(workflow_error)
    
    def _run_agent3(self, symbol: str, images: List[Path]) -> Dict[str, Any]:
        """
        Agent3 æ•°æ®æ ¡éªŒï¼ˆå¢å¼ºç‰ˆï¼‰
        
        æ–°å¢åŠŸèƒ½ï¼š
        1. è¯¦ç»†è®°å½•è¯·æ±‚å’Œå“åº”
        2. è‡ªåŠ¨è§„èŒƒåŒ–æ•°æ®ç»“æ„
        3. ä¿®å¤å¸¸è§æ ¼å¼é—®é¢˜
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            images: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            
        Returns:
            è§„èŒƒåŒ–åçš„ Agent3 å“åº”
        """
        from core.workflow.agent3_handler import Agent3Handler
        
        logger.info("ğŸ”„ [Agent3] æ•°æ®æ ¡éªŒï¼ˆå¢å¼ºç‰ˆï¼‰")
        
        # åˆ›å»ºå¤„ç†å™¨
        handler = Agent3Handler()
        
        # æ„å»º Prompt
        system_content = prompts.agent3_validate.get_system_prompt(self.env_vars)
        user_prompt = prompts.agent3_validate.get_user_prompt(
            symbol,
            [img.name for img in images]
        )
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        inputs = [
            {"role": "system", "content": system_content},
            {"role": "user", "content": user_prompt}
        ]
        
        # ç¼–ç æ‰€æœ‰å›¾ç‰‡
        valid_img_count = 0
        for path in images:
            b64_str = self.encode_image_to_base64(path)
            if b64_str:
                inputs.append({
                    "role": "user",
                    "content": [{"type": "image_url", "image_url": {"url": b64_str}}]
                })
                valid_img_count += 1
        
        if valid_img_count == 0:
            logger.error("âŒ æ²¡æœ‰æœ‰æ•ˆå›¾ç‰‡å¯å¤„ç†")
            return {}
        
        logger.info(f"ğŸ“¸ å·²ç¼–ç  {valid_img_count} å¼ å›¾ç‰‡")
        
        # è®°å½•è¯·æ±‚
        handler.log_request(symbol, inputs, valid_img_count)
        
        # è°ƒç”¨ API
        # response = self.agent_executor.execute_vision_agent(
        #     agent_name="agent3",
        #     inputs=inputs,
        #     json_schema=schemas.agent3_schema.get_schema()
        # )
        response = {
  "content": {
    "timestamp": "2025-11-30T08:00:34",
    "indices": {
      "QQQ": {
        "iv_14d": 0.18,
        "iv_7d": 0.16,
        "net_gex_idx": "positive_gamma",
        "spot_price_idx": 619.12
      },
      "SPX": {
        "iv_7d": 0.115,
        "net_gex_idx": "positive_gamma",
        "spot_price_idx": 4700.0,
        "iv_14d": 0.117
      }
    },
    "targets": {
      "atm_iv": {
        "iv_14d": 0.4,
        "iv_7d": 0.38,
        "iv_source": "7d"
      },
      "directional_metrics": {
        "dex_same_dir_pct": 0.63,
        "iv_path": "å‡",
        "iv_path_confidence": "high",
        "vanna_confidence": "medium",
        "vanna_dir": "up"
      },
      "gamma_metrics": {
        "weekly_data": {
          "cluster_strength": {
            "price": 180.0,
            "abs_gex": 40.0
          }
        },
        "gap_distance_dollar": 5.0,
        "monthly_data": {
          "cluster_strength": {
            "abs_gex": 70.86,
            "price": 180.0
          }
        },
        "nearby_peak": {
          "abs_gex": 20.0,
          "price": 175.0
        },
        "net_gex": "positive_gamma",
        "next_cluster_peak": {
          "abs_gex": 30.0,
          "price": 185.0
        },
        "spot_vs_trigger": "above",
        "vol_trigger": 172.5
      },
      "spot_price": 176.63,
      "symbol": "NVDA",
      "walls": {
        "put_wall": 170.0,
        "call_wall": 185.0,
        "major_wall": 180.0,
        "major_wall_type": "call"
      }
    }
  },
  "usage": {
    "input_tokens": 17651,
    "output_tokens": 316
  },
  "model": "gpt-4o-2024-08-06",
  "agent_name": "agent3",
  "provider": "openai"
}
        # print("<<<<<<<<<<<<<<<<< Agent3 response >>>>>>>>>>>", json.dumps(response))
        # è§£æå“åº”
        raw_content = response.get("content", {})
        
        parsed_data = {}
        
        if isinstance(raw_content, dict):
            parsed_data = raw_content
        elif isinstance(raw_content, str):
            # æ¸…æ´— Markdown æ ‡è®°
            try:
                clean_text = raw_content.strip()
                if clean_text.startswith("```json"):
                    clean_text = clean_text[7:]
                if clean_text.startswith("```"):
                    clean_text = clean_text[3:]
                if clean_text.endswith("```"):
                    clean_text = clean_text[:-3]
                parsed_data = json.loads(clean_text.strip())
            except json.JSONDecodeError as e:
                logger.error(f"âŒ JSON è§£æå¤±è´¥: {str(e)}")
                return {}
        else:
            logger.error(f"âŒ æœªçŸ¥çš„å“åº”ç±»å‹: {type(raw_content)}")
            return {}
        
        # è®°å½•åŸå§‹å“åº”
        handler.log_response(symbol, response, parsed_data)
        
        # è§„èŒƒåŒ–æ•°æ®ç»“æ„ï¼ˆä¿®å¤å¸¸è§é—®é¢˜ï¼‰
        logger.info("ğŸ”§ å¼€å§‹è§„èŒƒåŒ–æ•°æ®ç»“æ„")
        normalized_data = handler.normalize_structure(parsed_data)
        
        # æ‰“å°å¯¹æ¯”
        handler.print_detailed_comparison(parsed_data, normalized_data)
        
        logger.success("âœ… Agent3 æ•°æ®å¤„ç†å®Œæˆ")
        return normalized_data
    
    def _run_aggregator(self, agent3_result: Dict, symbol: str) -> Dict[str, Any]:
        """
        è¿è¡Œæ•°æ®èšåˆå™¨
        
        Args:
            agent3_result: Agent3 ç»“æœ
            state: å½“å‰çŠ¶æ€
            
        Returns:
            èšåˆç»“æœ
        """
        logger.info("ğŸ“¦ [Aggregator] æ•°æ®èšåˆ")
        
        result = self.agent_executor.execute_code_node(
            node_name="Aggregator",
            func=aggregator_main,
            agent3_output=agent3_result,
            symbol=symbol,
            **self.env_vars
        )
        return result
    
    def _run_calculator(self, agent3_result: Dict, symbol: str) -> Dict[str, Any]:
        """
        è¿è¡Œå­—æ®µè®¡ç®—å™¨
        
        Args:
            data: èšåˆåçš„æ•°æ®
            
        Returns:
            è®¡ç®—åçš„æ•°æ®
        """
        
        result = self.agent_executor.execute_code_node(
            node_name="Calculator",
            func=calculator_main,
            aggregated_data=agent3_result,
            symbol=symbol,
            **self.env_vars
        )
        return result
    
    def _handle_incomplete_data(self, aggregated_result: Dict) -> Dict[str, Any]:
        """
        å¤„ç†æ•°æ®ä¸å®Œæ•´çš„æƒ…å†µ
        
        Args:
            aggregated_result: èšåˆç»“æœ
            
        Returns:
            åŒ…å«è¡¥é½æŒ‡å¼•çš„ç»“æœ
        """
        return {
            "status": "incomplete",
            "guide": self._format_è¡¥é½æŒ‡å¼•(aggregated_result),
            "missing_count": aggregated_result.get("missing_count"),
            "raw_result": aggregated_result
        }
    
    def _format_è¡¥é½æŒ‡å¼•(self, result: Dict) -> str:
        """æ ¼å¼åŒ–è¡¥é½æŒ‡å¼•"""
        return f"""
==================================================
ğŸ“‹ æ•°æ®è¡¥é½æŒ‡å¼• ({result.get('user_guide_progress', '0%')})
==================================================

{result.get('user_guide_summary', '')}

ğŸ”´ å¿…é¡»è¡¥é½ (Critical):
{result.get('user_guide_priority_critical', 'æ— ')}

ğŸŸ  å»ºè®®è¡¥é½ (High):
{result.get('user_guide_priority_high', 'æ— ')}

ğŸŸ¡ å¯é€‰è¡¥é½ (Medium):
{result.get('user_guide_priority_medium', 'æ— ')}

ğŸ“ å†å²åˆå¹¶è®°å½•:
{result.get('user_guide_merge_log', '')}

ğŸ‘‰ ä¸‹ä¸€æ­¥: {result.get('user_guide_next_action', '')}
"""
    
    def _run_full_pipeline(
        self, 
        aggregated_result: Dict, 
        error_handler: ErrorHandler,
        market_params: Dict = None, 
        dyn_params: Dict = None
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´åˆ†ææµç¨‹
        
        Args:
            aggregated_result: èšåˆç»“æœ
            
        Returns:
            å®Œæ•´åˆ†æç»“æœ
        """
        logger.info("ğŸš€ å¼€å§‹å®Œæ•´åˆ†ææµç¨‹")
        # åˆ›å»ºå¹¶è¿è¡Œ Pipeline
        pipeline = AnalysisPipeline(
            agent_executor=self.agent_executor,
            cache_manager=self.cache_manager,
            env_vars=self.env_vars,
            enable_pretty_print=True,
            cache_file=self.engine.cache_file,  
            error_handler=error_handler,
            market_params=market_params,
            dyn_params=dyn_params
        )
        
        result = pipeline.run(aggregated_result)
        
        logger.success("âœ… å®Œæ•´åˆ†ææµç¨‹å®Œæˆ")
        
        return result