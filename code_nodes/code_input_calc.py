"""
è¾“å…¥æ–‡ä»¶è®¡ç®—å™¨ - å¤„ç† -i å‚æ•°çš„ symbol_datetime.json æ–‡ä»¶
è®¡ç®— cluster_strength_ratio å¹¶å†™å›æ–‡ä»¶

åˆå¹¶ä¼˜åŒ–ç‰ˆæœ¬ (v2.1):
- æ”¯æŒå¤šç§æ•°æ®ç»“æ„æ ¼å¼
- ä½¿ç”¨ top1/ENP æ–¹æ³•è®¡ç®—é›†ä¸­åº¦
- åŒæƒé‡å£å¾„å¯¹æ¯” (gex_total_m vs share_pct)
- [æ–°å¢] æ¿€æ´» ECR/SER/TSR å¾®è§‚ç»“æ„è®¡ç®—
- [æ–°å¢] å¢åŠ ç‰©ç†å«ä¹‰è½¬è¯‘å±‚ (Rigid/Brittle Wall)
"""
from __future__ import annotations
import json
import math
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from loguru import logger


def remove_json_comments(json_str: str) -> str:
    """
    ç§»é™¤ JSON å­—ç¬¦ä¸²ä¸­çš„ JavaScript é£æ ¼æ³¨é‡Š
    æ”¯æŒ // å•è¡Œæ³¨é‡Š
    """
    result = []
    in_string = False
    i = 0
    while i < len(json_str):
        char = json_str[i]
        
        # å¤„ç†å­—ç¬¦ä¸²
        if char == '"' and (i == 0 or json_str[i-1] != '\\'):
            in_string = not in_string
            result.append(char)
            i += 1
        # å¤„ç†æ³¨é‡Š
        elif not in_string and char == '/' and i + 1 < len(json_str) and json_str[i+1] == '/':
            # è·³è¿‡åˆ°è¡Œå°¾
            while i < len(json_str) and json_str[i] != '\n':
                i += 1
        else:
            result.append(char)
            i += 1
    
    return ''.join(result)


def load_json_with_comments(file_path: str) -> Dict[str, Any]:
    """
    åŠ è½½å¯èƒ½åŒ…å«æ³¨é‡Šçš„ JSON æ–‡ä»¶
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ç§»é™¤æ³¨é‡Š
    clean_content = remove_json_comments(content)
    
    return json.loads(clean_content)


def _get_panel(run: Dict[str, Any], name: str) -> Dict[str, Any]:
    """
    å…¼å®¹å¤šç§ç»“æ„ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
    1) run["metadata"]["panels"][name] - å­—å…¸æ ¼å¼ï¼ˆæ–°æ ¼å¼ï¼‰
    2) run["metadata"]["panels"] - åˆ—è¡¨æ ¼å¼ï¼ŒæŒ‰ panel_name åŒ¹é…
    3) run["panels"][name] - å­—å…¸æ ¼å¼
    4) run["panels"] - åˆ—è¡¨æ ¼å¼ï¼ŒæŒ‰ panel_name åŒ¹é…
    5) run[name] - ç›´æ¥åœ¨æ ¹èŠ‚ç‚¹
    """
    # ä¼˜å…ˆçº§1: metadata.panels å­—å…¸
    metadata = run.get("metadata", {})
    if isinstance(metadata.get("panels"), dict) and name in metadata["panels"]:
        return metadata["panels"][name] or {}
    
    # ä¼˜å…ˆçº§2: metadata.panels åˆ—è¡¨
    if isinstance(metadata.get("panels"), list):
        for panel in metadata["panels"]:
            if panel.get("panel_name") == name:
                return panel
    
    # ä¼˜å…ˆçº§3: panels å­—å…¸
    if isinstance(run.get("panels"), dict) and name in run["panels"]:
        return run["panels"][name] or {}
    
    # ä¼˜å…ˆçº§4: panels åˆ—è¡¨
    if isinstance(run.get("panels"), list):
        for panel in run["panels"]:
            if panel.get("panel_name") == name:
                return panel
    
    # ä¼˜å…ˆçº§5: æ ¹èŠ‚ç‚¹ç›´æ¥åŒ¹é…
    return run.get(name, {}) or {}


# ============================================================
# åŸºç¡€å·¥å…·å‡½æ•°
# ============================================================

def _safe_is_number(x) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆæ•°å­—ï¼ˆint æˆ– floatï¼Œä¸”é NaNï¼‰"""
    return isinstance(x, (int, float)) and not math.isnan(x)


def _safe_float(x: Any) -> Optional[float]:
    """å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•°"""
    try:
        if x is None:
            return None
        v = float(x)
        if math.isnan(v) or math.isinf(v):
            return None
        return v
    except Exception:
        return None


def _normalize(weights: List[float]) -> Optional[List[float]]:
    """å½’ä¸€åŒ–éè´Ÿæƒé‡ï¼Œä½¿å…¶å’Œä¸º1ã€‚æ— æ•ˆæˆ–é›¶å’Œæ—¶è¿”å›None"""
    if not weights:
        return None
    clean = []
    for w in weights:
        if w is None:
            return None
        if w < 0:
            return None
        clean.append(float(w))
    s = sum(clean)
    if s <= 0:
        return None
    return [w / s for w in clean]


def _entropy(p: List[float]) -> float:
    """è‡ªç„¶å¯¹æ•°ç†µï¼Œpå¿…é¡»å’Œä¸º1"""
    ent = 0.0
    for x in p:
        if x > 0:
            ent -= x * math.log(x)
    return ent


def _entropy_log2(p: List[float]) -> float:
    """ä»¥2ä¸ºåº•çš„ç†µï¼Œpå¿…é¡»å’Œä¸º1"""
    ent = 0.0
    for x in p:
        if x > 0:
            ent -= x * math.log(x, 2.0)
    return ent


def _hhi(p: List[float]) -> float:
    """HHIæŒ‡æ•°"""
    return sum(x * x for x in p)


def _topk_sum_sorted(p: List[float], k: int) -> float:
    """å‰kå¤§å…ƒç´ ä¹‹å’Œ"""
    if not p:
        return 0.0
    ps = sorted(p, reverse=True)
    return sum(ps[:k])


def _tv_distance(p: List[float], q: List[float]) -> float:
    """Total variation distanceï¼ŒèŒƒå›´[0,1]"""
    return 0.5 * sum(abs(a - b) for a, b in zip(p, q))


def _cosine_similarity(p: List[float], q: List[float]) -> float:
    """ä½™å¼¦ç›¸ä¼¼åº¦"""
    dot = sum(a * b for a, b in zip(p, q))
    np = math.sqrt(sum(a * a for a in p))
    nq = math.sqrt(sum(b * b for b in q))
    if np == 0 or nq == 0:
        return 0.0
    return dot / (np * nq)


def _metrics_from_norm_weights(p: List[float]) -> Dict[str, float]:
    """åŸºäºå½’ä¸€åŒ–æƒé‡pè®¡ç®—æ ¸å¿ƒæŒ‡æ ‡"""
    n = len(p)
    hhi = _hhi(p)
    enp = (1.0 / hhi) if hhi > 0 else float("inf")
    ent = _entropy(p)
    ent_norm = ent / math.log(n) if n > 1 else 0.0

    return {
        "top1": _topk_sum_sorted(p, 1),
        "top2": _topk_sum_sorted(p, 2),
        "hhi": hhi,
        "enp": enp,
        "entropy": ent,
        "entropy_norm": ent_norm,
    }


# ============================================================
# Dataclass å®šä¹‰ (æ–°å¢)
# ============================================================

@dataclass
class PanelMetrics:
    """å•ä¸ª panel çš„é›†ä¸­åº¦æŒ‡æ ‡"""
    panel_name: str
    horizon_arg: str
    n: int
    weight_source: str  # "gex_total_m_abs" / "share_pct" / "none"
    top1: float
    top2: float
    hhi: float
    enp: float
    entropy: float
    entropy_norm: float


@dataclass
class ClusterAssessment:
    """é›†ç¾¤é›†ä¸­åº¦è¯„ä¼°ç»“æœ"""
    panels: List[PanelMetrics]
    avg_top1: float
    avg_enp: float
    tier: str
    score: float


# ============================================================
# æƒé‡é€‰æ‹©é€»è¾‘ (æ–°å¢)
# ============================================================

def choose_weights_for_panel(rows: List[Dict]) -> Tuple[Optional[List[float]], str]:
    """
    å¯¹ä¸€ä¸ª panel é€‰æ‹©æƒé‡ï¼š
    1) ä¼˜å…ˆ abs(gex_total_m)ï¼Œè‹¥æœ‰æ­£æ€»å’Œåˆ™ç”¨å®ƒï¼›
    2) å¦åˆ™é€€å› share_pctï¼›
    3) å†å¦åˆ™è¿”å› (None, "none")ã€‚
    è¿”å›çš„ weights å·²ç»å½’ä¸€åŒ–ï¼Œé•¿åº¦ç­‰äº rows é•¿åº¦ã€‚
    """
    if not rows:
        return None, "none"

    # 1) å°è¯•ä½¿ç”¨ abs(gex_total_m)
    gex_abs: List[float] = []
    for r in rows:
        v = r.get("gex_total_m")
        if _safe_is_number(v):
            gex_abs.append(abs(float(v)))
        else:
            gex_abs.append(0.0)

    gex_sum = sum(gex_abs)
    if gex_sum > 0:
        weights = [v / gex_sum for v in gex_abs]
        return weights, "gex_total_m_abs"

    # 2) é€€å›ä½¿ç”¨ share_pct
    share_vals: List[float] = []
    for r in rows:
        v = r.get("share_pct")
        if _safe_is_number(v):
            val = float(v)
            if val < 0:
                val = 0.0
            share_vals.append(val)
        else:
            share_vals.append(0.0)

    share_sum = sum(share_vals)
    if share_sum > 0:
        weights = [v / share_sum for v in share_vals]
        return weights, "share_pct"

    # 3) éƒ½ä¸å¯ç”¨
    return None, "none"


# ============================================================
# å•ä¸ª panel æŒ‡æ ‡è®¡ç®— (æ–°å¢åŸºäº dataclass çš„ç‰ˆæœ¬)
# ============================================================

def compute_panel_metrics(panel: Dict) -> PanelMetrics:
    """
    è®¡ç®—å•ä¸ª panel çš„æŒ‡æ ‡ï¼Œè¿”å› PanelMetrics dataclass
    ä½¿ç”¨ choose_weights_for_panel è¿›è¡Œæƒé‡é€‰æ‹©
    """
    panel_name = str(panel.get("panel_name", ""))
    horizon_arg = str(panel.get("horizon_arg", ""))
    rows: List[Dict] = panel.get("rows") or []

    n = len(rows)
    weights, source = choose_weights_for_panel(rows)

    if not rows or weights is None:
        # æ— æœ‰æ•ˆæƒé‡çš„å…œåº•ç»“æœ
        return PanelMetrics(
            panel_name=panel_name,
            horizon_arg=horizon_arg,
            n=n,
            weight_source=source,
            top1=0.0,
            top2=0.0,
            hhi=0.0,
            enp=math.inf,
            entropy=0.0,
            entropy_norm=0.0,
        )

    # è®¡ç®— top1 / top2
    sorted_w = sorted(weights, reverse=True)
    top1 = sorted_w[0]
    top2 = sorted_w[1] if len(sorted_w) > 1 else 0.0

    # HHI / ENP
    hhi = sum(w * w for w in weights)
    enp = 1.0 / hhi if hhi > 0 else math.inf

    # entropy / normalized entropy (ä»¥2ä¸ºåº•)
    entropy = 0.0
    for w in weights:
        if w > 0:
            entropy -= w * math.log(w, 2.0)
    if n > 1:
        entropy_norm = entropy / math.log(n, 2.0)
    else:
        # n=1 æ—¶ï¼Œentropy ä¸å‚ä¸åç»­åˆ¤å®šï¼Œè¿™é‡Œç»™ 0 å³å¯
        entropy_norm = 0.0

    return PanelMetrics(
        panel_name=panel_name,
        horizon_arg=horizon_arg,
        n=n,
        weight_source=source,
        top1=top1,
        top2=top2,
        hhi=hhi,
        enp=enp,
        entropy=entropy,
        entropy_norm=entropy_norm,
    )


# ============================================================
# èšåˆ & åˆ†æ¡£é€»è¾‘ (æ–°å¢)
# ============================================================

def assess_cluster_strength(panels: List[Dict]) -> ClusterAssessment:
    """
    è¯„ä¼°é›†ç¾¤é›†ä¸­åº¦å¼ºåº¦
    
    åˆ†æ¡£è§„åˆ™ï¼š
      - strong (1.35): avg_enp <= 1.7
      - medium (1.20): avg_enp <= 2.3
      - weak (1.05): else
    
    Args:
        panels: panel åˆ—è¡¨ï¼Œæ¯ä¸ª panel æ˜¯åŒ…å« panel_name å’Œ rows çš„å­—å…¸
        
    Returns:
        ClusterAssessment dataclass
    """
    panel_metrics_list: List[PanelMetrics] = [compute_panel_metrics(p) for p in panels]

    # åªå¯¹æœ‰æœ‰æ•ˆæƒé‡çš„ panel åšå¹³å‡
    valid_for_top1 = [pm for pm in panel_metrics_list if pm.weight_source != "none" and pm.n > 0]
    valid_for_enp = [pm for pm in panel_metrics_list if pm.weight_source != "none" and math.isfinite(pm.enp)]

    if valid_for_top1:
        avg_top1 = sum(pm.top1 for pm in valid_for_top1) / len(valid_for_top1)
    else:
        avg_top1 = 0.0

    if valid_for_enp:
        avg_enp = sum(pm.enp for pm in valid_for_enp) / len(valid_for_enp)
    else:
        avg_enp = math.inf

    # åˆ†æ¡£è§„åˆ™ï¼ˆåŸºäº avg_enpï¼‰
    if avg_enp <= 1.7:
        tier = "strong"
        score = 1.35
    elif avg_enp <= 2.3:
        tier = "medium"
        score = 1.20
    else:
        tier = "weak"
        score = 1.05

    return ClusterAssessment(
        panels=panel_metrics_list,
        avg_top1=avg_top1,
        avg_enp=avg_enp,
        tier=tier,
        score=score,
    )


# ============================================================
# åŸæœ‰ panel_metrics å‡½æ•° (ä¿ç•™å…¼å®¹æ€§ï¼Œè¿”å›å­—å…¸æ ¼å¼)
# ============================================================

def panel_metrics(
    panel: Dict[str, Any],
    main_weight_key: str = "gex_total_m",
    alt_weight_key: Optional[str] = "share_pct",
) -> Dict[str, Any]:
    """
    è®¡ç®—å•ä¸ªpanelçš„æŒ‡æ ‡ï¼ˆå­—å…¸æ ¼å¼è¾“å‡ºï¼Œä¿æŒå‘åå…¼å®¹ï¼‰
    - main: åŸºäº main_weight_key å½’ä¸€åŒ–ï¼ˆå¯¹ gex_total_m å–ç»å¯¹å€¼ï¼‰
    - alt: åŸºäº alt_weight_key å½’ä¸€åŒ– + ä¸mainçš„åå·®
    """
    panel_name = panel.get("panel_name")
    rows = panel.get("rows") or []
    if not isinstance(rows, list):
        rows = []

    # æŒ‰è¡Œé¡ºåºæå–åŸå§‹æƒé‡
    main_raw: List[float] = []
    alt_raw: List[float] = []

    for r in rows:
        mw = _safe_float(r.get(main_weight_key))
        if mw is None:
            mw = 0.0
        # å¯¹ gex_total_m å–ç»å¯¹å€¼ï¼ˆä¸ choose_weights_for_panel ä¿æŒä¸€è‡´ï¼‰
        if main_weight_key == "gex_total_m":
            mw = abs(mw)
        main_raw.append(mw)

        if alt_weight_key:
            aw = _safe_float(r.get(alt_weight_key))
            if aw is None:
                aw = 0.0
            # share_pct è´Ÿå€¼å¤„ç†ä¸º 0
            if alt_weight_key == "share_pct" and aw < 0:
                aw = 0.0
            alt_raw.append(aw)

    main_norm = _normalize(main_raw)
    main_out: Dict[str, Any]
    if main_norm is None:
        main_out = {
            "n": len(rows),
            "total": float(sum(main_raw)) if main_raw else 0.0,
            "top1": 0.0,
            "top2": 0.0,
            "hhi": 0.0,
            "enp": float("inf"),
            "entropy": 0.0,
            "entropy_norm": 0.0,
        }
    else:
        main_out = {
            "n": len(rows),
            "total": float(sum(main_raw)),
            **_metrics_from_norm_weights(main_norm),
        }

    alt_out = None
    if alt_weight_key:
        alt_norm = _normalize(alt_raw)
        if alt_norm is not None:
            alt_metrics = {
                "n": len(rows),
                "total": float(sum(alt_raw)),
                **_metrics_from_norm_weights(alt_norm),
            }
            mismatch = None
            if main_norm is not None and len(main_norm) == len(alt_norm):
                mismatch = {
                    "tv": _tv_distance(main_norm, alt_norm),
                    "cosine": _cosine_similarity(main_norm, alt_norm),
                }
            alt_out = {
                "weight_key": alt_weight_key,
                "metrics": alt_metrics,
                "mismatch": mismatch,
            }

    return {
        "panel_name": panel_name,
        "horizon_arg": panel.get("horizon_arg"),
        "weight_key_used": main_weight_key,
        "main": main_out,
        "alt": alt_out,
    }


def _pick_alt_top(panel_dict: Dict[str, Any]) -> Tuple[Optional[float], Optional[float]]:
    """æå–å¤‡é€‰æƒé‡çš„top1/top2"""
    alt = panel_dict.get("alt")
    if not alt or not alt.get("metrics"):
        return None, None
    m = alt["metrics"]
    return m.get("top1"), m.get("top2")


def compute_cluster_strength_assessment(
    run: Dict[str, Any],
    main_weight_key: str = "gex_total_m",
    alt_weight_key: str = "share_pct",
) -> Dict[str, Any]:
    """
    ç”Ÿæˆæœ€ç»ˆè¯„ä¼°ç»“æœï¼ˆå­—å…¸æ ¼å¼ï¼Œä¿æŒå‘åå…¼å®¹ï¼‰
    
    åˆ†å±‚è§„åˆ™ (Heuristic tiering):
      - strong (1.35): avg_top1 >= 0.65 OR avg_enp <= 1.8
      - medium (1.20): avg_top1 >= 0.50 OR avg_enp <= 2.3
      - weak (1.05): else
    """
    # è·å–panelsæ•°æ®
    metadata = run.get("metadata", {})
    panels = metadata.get("panels") or run.get("panels") or []
    
    by_name = {p.get("panel_name"): p for p in panels if isinstance(p, dict)}

    short = panel_metrics(by_name.get("short", {"panel_name": "short", "rows": []}),
                          main_weight_key=main_weight_key, alt_weight_key=alt_weight_key)
    mid = panel_metrics(by_name.get("mid", {"panel_name": "mid", "rows": []}),
                        main_weight_key=main_weight_key, alt_weight_key=alt_weight_key)
    long = panel_metrics(by_name.get("long", {"panel_name": "long", "rows": []}),
                         main_weight_key=main_weight_key, alt_weight_key=alt_weight_key)

    panel_list = [short, mid, long]

    # èšåˆè®¡ç®—
    main_top1s = [p["main"]["top1"] for p in panel_list if math.isfinite(p["main"]["top1"])]
    main_enps = [p["main"]["enp"] for p in panel_list if math.isfinite(p["main"]["enp"])]

    avg_top1 = sum(main_top1s) / len(main_top1s) if main_top1s else 0.0
    avg_enp = sum(main_enps) / len(main_enps) if main_enps else float("inf")

    # åˆ†å±‚åˆ¤å®š
    if (avg_top1 >= 0.65) or (avg_enp <= 1.8):
        tier, score = "strong", 1.35
    elif (avg_top1 >= 0.50) or (avg_enp <= 2.3):
        tier, score = "medium", 1.20
    else:
        tier, score = "weak", 1.05

    # æ—¥å¿—è¾“å‡º
    logger.info(f"ğŸ“Š é›†ä¸­åº¦æŒ‡æ ‡ (top1/ENP æ–¹æ³•):")
    logger.info(f"   Short: top1={short['main']['top1']:.4f}, enp={short['main']['enp']:.2f}, n={short['main']['n']}")
    logger.info(f"   Mid:   top1={mid['main']['top1']:.4f}, enp={mid['main']['enp']:.2f}, n={mid['main']['n']}")
    logger.info(f"   Long:  top1={long['main']['top1']:.4f}, enp={long['main']['enp']:.2f}, n={long['main']['n']}")
    logger.info(f"   å¹³å‡: avg_top1={avg_top1:.4f}, avg_enp={avg_enp:.2f}")
    logger.info(f"âœ… åˆ¤å®šä¸º {tier} æ¡£é›†ä¸­åº¦ ({score})")

    return {
        "tier": tier,
        "score": score,
        "cluster_strength_ratio": score,

        "panels": {"short": short, "mid": mid, "long": long},

        "summary": {
            "avg_top1_main": avg_top1,
            "avg_enp_main": avg_enp,
        },

        "top_summary": {
            "short": {
                "main_key": short["weight_key_used"],
                "top1": short["main"]["top1"],
                "top2": short["main"]["top2"],
                "enp": short["main"]["enp"],
                "n": short["main"]["n"],
                "alt_top1": _pick_alt_top(short)[0],
                "alt_top2": _pick_alt_top(short)[1],
            },
            "mid": {
                "main_key": mid["weight_key_used"],
                "top1": mid["main"]["top1"],
                "top2": mid["main"]["top2"],
                "enp": mid["main"]["enp"],
                "n": mid["main"]["n"],
                "alt_top1": _pick_alt_top(mid)[0],
                "alt_top2": _pick_alt_top(mid)[1],
            },
            "long": {
                "main_key": long["weight_key_used"],
                "top1": long["main"]["top1"],
                "top2": long["main"]["top2"],
                "enp": long["main"]["enp"],
                "n": long["main"]["n"],
                "alt_top1": _pick_alt_top(long)[0],
                "alt_top2": _pick_alt_top(long)[1],
            },
        },
    }


def compute_cluster_strength_assessment_v2(
    run: Dict[str, Any],
) -> ClusterAssessment:
    """
    ç”Ÿæˆè¯„ä¼°ç»“æœï¼ˆä½¿ç”¨æ–°çš„ dataclass æ ¼å¼ï¼‰
    
    ä½¿ç”¨ choose_weights_for_panel è¿›è¡Œæƒé‡é€‰æ‹©ï¼š
    1) ä¼˜å…ˆ abs(gex_total_m)
    2) å¦åˆ™é€€å› share_pct
    
    åˆ†æ¡£è§„åˆ™ï¼š
      - strong (1.35): avg_enp <= 1.7
      - medium (1.20): avg_enp <= 2.3
      - weak (1.05): else
    """
    # è·å–panelsæ•°æ®
    metadata = run.get("metadata", {})
    panels = metadata.get("panels") or run.get("panels") or []
    
    if isinstance(panels, dict):
        panels = list(panels.values())
    
    return assess_cluster_strength(panels)


# ============================================================
# å…¼å®¹æ—§æ¥å£
# ============================================================

def compute_cluster_strength_ratio(run: Dict[str, Any]) -> Tuple[Optional[float], Dict[str, Any]]:
    """
    å…¼å®¹æ—§æ¥å£ï¼Œè¿”å› (cluster_strength_ratio, metrics_dict)
    """
    assessment = compute_cluster_strength_assessment(run)
    return assessment["cluster_strength_ratio"], assessment


def compute_ECR_SER_TSR(run: Dict[str, Any]) -> Dict[str, Any]:
    """
    å…¼å®¹æ—§æ¥å£ï¼Œè¿”å› ECR/SER/TSRï¼ˆåŸºäºHHIå½’ä¸€åŒ–ï¼‰
    åŒæ—¶è¿”å›æ–°çš„ top1/enp æŒ‡æ ‡
    """
    assessment = compute_cluster_strength_assessment(run)
    panels = assessment["panels"]
    
    # è®¡ç®—å½’ä¸€åŒ–HHI (ç”¨äºæ—§æ¥å£å…¼å®¹)
    def _normalized_hhi_from_panel(panel_dict: Dict[str, Any]) -> Optional[float]:
        main = panel_dict.get("main", {})
        hhi = main.get("hhi", 0)
        n = main.get("n", 0)
        if n <= 1:
            return 1.0 if n == 1 else None
        if hhi == 0:
            return None
        norm = (hhi - 1.0 / n) / (1.0 - 1.0 / n)
        return float(max(0.0, min(1.0, norm)))
    
    return {
        "ECR": _normalized_hhi_from_panel(panels["short"]),
        "SER": _normalized_hhi_from_panel(panels["mid"]),
        "TSR": _normalized_hhi_from_panel(panels["long"]),
        "n_short": panels["short"]["main"]["n"],
        "n_mid": panels["mid"]["main"]["n"],
        "n_long": panels["long"]["main"]["n"],
        # æ–°å¢æŒ‡æ ‡
        "top1_short": panels["short"]["main"]["top1"],
        "top1_mid": panels["mid"]["main"]["top1"],
        "top1_long": panels["long"]["main"]["top1"],
        "enp_short": panels["short"]["main"]["enp"],
        "enp_mid": panels["mid"]["main"]["enp"],
        "enp_long": panels["long"]["main"]["enp"],
    }


def interpret_micro_structure(metrics: Dict[str, Any]) -> Dict[str, Any]:
    """
    [æ–°å¢] å¾®è§‚ç»“æ„ç‰©ç†å«ä¹‰è½¬è¯‘å±‚
    å°† ECR/SER/TSR æ•°å€¼è½¬åŒ–ä¸º LLM å¯ç†è§£çš„ç‰©ç†çŠ¶æ€
    """
    ecr = metrics.get("ECR") or 0
    ser = metrics.get("SER") or 0
    tsr = metrics.get("TSR") or 0
    
    # 1. å¢™ä½“ç‰©ç†å±æ€§ (Wall Physics) - åŸºäº ECR (é›†ä¸­åº¦)
    # ECR è¶Šé«˜ï¼Œç­¹ç è¶Šé›†ä¸­åœ¨å•ä¸€æœŸé™ï¼Œå¢™è¶Šç¡¬(Rigid)ï¼Œå®¹æ˜“ Pinning
    if ecr > 0.65:
        wall_type = "Rigid (åˆšæ€§å¢™)"
        breakout_difficulty = "High"
        wall_note = "ç­¹ç é«˜åº¦é›†ä¸­ï¼Œçªç ´éœ€å·¨å¤§åŠ¨èƒ½ï¼Œå®¹æ˜“å¼•å‘Gamma Pinning"
    elif ecr < 0.35:
        wall_type = "Brittle (è„†æ€§å¢™)"
        breakout_difficulty = "Low"
        wall_note = "ç­¹ç åˆ†æ•£ï¼Œå¢™ä½“è–„å¼±ï¼Œå®¹æ˜“è¢«ç©¿é€"
    else:
        wall_type = "Elastic (å¼¹æ€§å¢™)"
        breakout_difficulty = "Medium"
        wall_note = "ç»“æ„å‡è¡¡ï¼Œæä¾›æ­£å¸¸é˜»åŠ›"

    # 2. ç»­èˆª/æ¥åŠ›èƒ½åŠ› (Sustain Potential) - åŸºäº SER (æ¬¡å¼ºç»“æ„)
    # SER è¶Šé«˜ï¼Œè¯´æ˜æ¬¡å¼ºæœŸé™æœ‰æ¥åŠ›èƒ½åŠ›ï¼Œè¶‹åŠ¿å®¹æ˜“å»¶ç»­
    if ser > 0.55:
        sustain_potential = "High"
        sustain_note = "æ¬¡çº§æœŸé™ç»“æ„å®Œæ•´ï¼Œçªç ´åæœ‰æ¥åŠ›(Relay)ï¼Œè¶‹åŠ¿å»¶ç»­æ€§å¼º"
    else:
        sustain_potential = "Low"
        sustain_note = "æ¬¡çº§ç»“æ„ç©ºè™šï¼Œè­¦æƒ•å‡çªç ´(False Breakout)æˆ–ç¼ºä¹åç»­åŠ¨èƒ½"

    return {
        "wall_type": wall_type,
        "breakout_difficulty": breakout_difficulty,
        "sustain_potential": sustain_potential,
        "interpretation": f"{wall_type}ï¼Œçªç ´éš¾åº¦{breakout_difficulty}ã€‚{sustain_note}ã€‚",
        "raw_metrics": {
            "ECR": round(ecr, 3),
            "SER": round(ser, 3),
            "TSR": round(tsr, 3)
        }
    }


# ============================================================
# InputFileCalculator ç±»
# ============================================================

class InputFileCalculator:
    """
    è¾“å…¥æ–‡ä»¶è®¡ç®—å™¨
    å¤„ç† -i å‚æ•°æŒ‡å®šçš„ symbol_datetime.json æ–‡ä»¶
    """
    
    def __init__(self, input_path: str):
        """
        åˆå§‹åŒ–è®¡ç®—å™¨
        
        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
        """
        self.input_path = Path(input_path)
        self.data: Dict[str, Any] = {}
        self._assessment: Dict[str, Any] = {}
        self._cluster_assessment: Optional[ClusterAssessment] = None
        
    def load(self) -> Dict[str, Any]:
        """
        åŠ è½½è¾“å…¥æ–‡ä»¶
        """
        if not self.input_path.exists():
            raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {self.input_path}")
        
        self.data = load_json_with_comments(str(self.input_path))
        logger.info(f"ğŸ“‚ æˆåŠŸåŠ è½½è¾“å…¥æ–‡ä»¶: {self.input_path}")
        
        # æå–å…ƒä¿¡æ¯ç”¨äºæ—¥å¿—
        metadata = self.data.get("metadata", {})
        spec_targets = self.data.get("spec", {}).get("targets", {})
        symbol = spec_targets.get("symbol") or metadata.get("symbol", "UNKNOWN")
        as_of = metadata.get("as_of", "N/A")
        logger.info(f"ğŸ¯ æ ‡çš„: {symbol}, æ—¥æœŸ: {as_of}")
        
        return self.data
    
    def calculate(self) -> Dict[str, Any]:
        """
        æ‰§è¡Œè®¡ç®—
        
        Returns:
            è®¡ç®—ç»“æœå­—å…¸
        """
        if not self.data:
            self.load()
        
        # æ£€æŸ¥ panels æ•°æ®æ˜¯å¦å­˜åœ¨
        metadata = self.data.get("metadata", {})
        panels = metadata.get("panels") or self.data.get("panels")
        if not panels:
            raise ValueError("è¾“å…¥æ–‡ä»¶ç¼ºå°‘ panels å­—æ®µ")
        
        logger.info(f"ğŸ“‹ å‘ç° {len(panels) if isinstance(panels, list) else 'N/A'} ä¸ª panel")
        
        # æ‰§è¡Œè¯„ä¼°è®¡ç®—ï¼ˆå­—å…¸æ ¼å¼ï¼‰
        self._assessment = compute_cluster_strength_assessment(self.data)
        
        # åŒæ—¶æ‰§è¡Œæ–°çš„ dataclass æ ¼å¼è¯„ä¼°
        self._cluster_assessment = compute_cluster_strength_assessment_v2(self.data)
        
        # [æ–°å¢] è®¡ç®—å¾®è§‚ç»“æ„æŒ‡æ ‡ (ECR/SER/TSR) å¹¶è½¬è¯‘
        raw_micro = compute_ECR_SER_TSR(self.data)
        micro_structure = interpret_micro_structure(raw_micro)

        # æå–å…³é”®ç»“æœ
        summary = self._assessment["summary"]
        top_summary = self._assessment["top_summary"]
        
        result = {
            "cluster_strength_ratio": self._assessment["cluster_strength_ratio"],
            "tier": self._assessment["tier"],
            "avg_top1": summary["avg_top1_main"],
            "avg_enp": summary["avg_enp_main"],
            "micro_structure": micro_structure,  # [æ–°å¢]
            # å„panelè¯¦æƒ…
            "short": {
                "top1": top_summary["short"]["top1"],
                "top2": top_summary["short"]["top2"],
                "enp": top_summary["short"]["enp"],
                "n": top_summary["short"]["n"],
            },
            "mid": {
                "top1": top_summary["mid"]["top1"],
                "top2": top_summary["mid"]["top2"],
                "enp": top_summary["mid"]["enp"],
                "n": top_summary["mid"]["n"],
            },
            "long": {
                "top1": top_summary["long"]["top1"],
                "top2": top_summary["long"]["top2"],
                "enp": top_summary["long"]["enp"],
                "n": top_summary["long"]["n"],
            },
        }
        
        return result
    
    def calculate_v2(self) -> ClusterAssessment:
        """
        æ‰§è¡Œè®¡ç®—ï¼ˆè¿”å› ClusterAssessment dataclassï¼‰
        
        Returns:
            ClusterAssessment å¯¹è±¡
        """
        if not self.data:
            self.load()
        
        # æ£€æŸ¥ panels æ•°æ®æ˜¯å¦å­˜åœ¨
        metadata = self.data.get("metadata", {})
        panels = metadata.get("panels") or self.data.get("panels")
        if not panels:
            raise ValueError("è¾“å…¥æ–‡ä»¶ç¼ºå°‘ panels å­—æ®µ")
        
        if isinstance(panels, dict):
            panels = list(panels.values())
        
        self._cluster_assessment = assess_cluster_strength(panels)
        return self._cluster_assessment
    
    def get_cluster_assessment(self) -> Optional[ClusterAssessment]:
        """
        è·å– ClusterAssessment ç»“æœ
        
        Returns:
            ClusterAssessment å¯¹è±¡ï¼Œå¦‚æœè¿˜æœªè®¡ç®—åˆ™è¿”å› None
        """
        return self._cluster_assessment
    
    def write_back(self, output_path: str = None) -> str:
        """
        å°†è®¡ç®—ç»“æœå†™å›æ–‡ä»¶
        """
        if not self.data:
            self.load()
        
        # æ‰§è¡Œè®¡ç®—ï¼ˆå¦‚æœè¿˜æ²¡è®¡ç®—è¿‡ï¼‰
        if not self._assessment:
            self.calculate()
        
        ratio = self._assessment.get("cluster_strength_ratio")
        
        # æ›´æ–°æ•°æ®ç»“æ„
        if "spec" not in self.data:
            self.data["spec"] = {}
        if "targets" not in self.data["spec"]:
            self.data["spec"]["targets"] = {}
        if "gamma_metrics" not in self.data["spec"]["targets"]:
            self.data["spec"]["targets"]["gamma_metrics"] = {}
        
        self.data["spec"]["targets"]["gamma_metrics"]["cluster_strength_ratio"] = ratio
        
        # [æ–°å¢] å†™å…¥å¾®è§‚ç»“æ„åˆ†æ
        if self._assessment:
             # é‡æ–°è·å–(ç¡®ä¿å·²æœ‰)
             raw_micro = compute_ECR_SER_TSR(self.data)
             micro_data = interpret_micro_structure(raw_micro)
             self.data["spec"]["targets"]["gamma_metrics"]["micro_structure"] = micro_data

        # å¦‚æœæœ‰ ClusterAssessment ç»“æœï¼Œä¹Ÿå†™å…¥
        if self._cluster_assessment:
            self.data["spec"]["targets"]["gamma_metrics"]["cluster_assessment"] = {
                "tier": self._cluster_assessment.tier,
                "score": self._cluster_assessment.score,
                "avg_top1": self._cluster_assessment.avg_top1,
                "avg_enp": self._cluster_assessment.avg_enp,
                "panels": [asdict(pm) for pm in self._cluster_assessment.panels],
            }
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        out_path = Path(output_path) if output_path else self.input_path
        
        # å†™å…¥æ–‡ä»¶
        with open(out_path, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, indent=2, ensure_ascii=False)
        
        logger.success(f"ğŸ’¾ è®¡ç®—ç»“æœå·²å†™å›: {out_path}")
        
        return str(out_path)


# ============================================================
# å…¥å£å‡½æ•°
# ============================================================

def calculate_and_update(input_file: Path) -> Dict[str, Any]:
    """
    ä¸»å‡½æ•°ï¼šè¯»å– symbol_datetime.jsonï¼Œè®¡ç®— cluster_strength_ratio å¹¶å†™å›
    """
    try:
        calculator = InputFileCalculator(str(input_file))
        calculator.load()
        result = calculator.calculate()
        calculator.write_back()
        
        # æå–å…ƒä¿¡æ¯
        metadata = calculator.data.get("metadata", {})
        spec_targets = calculator.data.get("spec", {}).get("targets", {})
        symbol = spec_targets.get("symbol") or metadata.get("symbol", "UNKNOWN")
        as_of = metadata.get("as_of", "N/A")
        
        return {
            "status": "success",
            "symbol": symbol,
            "as_of": as_of,
            "cluster_strength_ratio": result["cluster_strength_ratio"],
            "tier": result["tier"],
            "summary": {
                "avg_top1": result["avg_top1"],
                "avg_enp": result["avg_enp"],
            },
            "panels": {
                "short": result["short"],
                "mid": result["mid"],
                "long": result["long"],
            },
            "micro_structure": result.get("micro_structure"), # [æ–°å¢]
            "file_path": str(input_file)
        }
    
    except Exception as e:
        logger.exception("âŒ æ‰§è¡Œå¤±è´¥")
        return {
            "status": "error",
            "error_message": str(e),
            "error_type": type(e).__name__
        }


def process_input_file(input_path: str, output_path: str = None) -> Dict[str, Any]:
    """
    å¤„ç†è¾“å…¥æ–‡ä»¶çš„ä¾¿æ·å‡½æ•°
    """
    calculator = InputFileCalculator(input_path)
    calculator.load()
    result = calculator.calculate()
    calculator.write_back(output_path)
    return result


def main(input_path: str, output_path: str = None, **kwargs) -> Dict[str, Any]:
    """
    ä¸»å…¥å£å‡½æ•° (Code Node å…¥å£)
    """
    try:
        file_path = Path(input_path)
        return calculate_and_update(file_path)
    except Exception as e:
        logger.exception("âŒ æ‰§è¡Œå¤±è´¥")
        return {
            "status": "error",
            "error_message": str(e),
            "error_type": type(e).__name__
        }