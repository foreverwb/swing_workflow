"""
æ•°æ®èšåˆèŠ‚ç‚¹ - CODE_AGGREGATOR (Node 1009)
å®ç°å¢é‡æ•°æ®ç´¯ç§¯å’Œæ™ºèƒ½è¡¥é½æŒ‡å¼•
"""

import json
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional


class DataAggregator:
    """æ•°æ®èšåˆå¼•æ“,å®ç°å¢é‡åˆå¹¶å’Œè¡¥é½æŒ‡å¼•ç”Ÿæˆ"""
    
    def __init__(self, config):
        self.config = config
    
    def process(
        self, 
        agent3_output: dict,
        first_parse_data: str = "",
        current_symbol: str = "",
        data_status: str = "initial",
        missing_count: int = 0
    ) -> Dict[str, Any]:
        """
        ä¸»å¤„ç†æµç¨‹
        
        Args:
            agent3_output: Agent 3 çš„æ•°æ®æ ¡éªŒç»“æœ
            first_parse_data: ç¼“å­˜çš„é¦–æ¬¡è§£ææ•°æ® (JSONå­—ç¬¦ä¸²)
            current_symbol: ç¼“å­˜çš„è‚¡ç¥¨ä»£ç 
            data_status: ç¼“å­˜çš„æ•°æ®çŠ¶æ€ (initial/awaiting_data/ready/error)
            missing_count: ç¼“å­˜çš„ç¼ºå¤±å­—æ®µæ•°é‡
        
        Returns:
            {
                "result": åˆå¹¶åçš„å®Œæ•´æ•°æ® (JSONå­—ç¬¦ä¸²),
                "first_parse_data": æ›´æ–°åçš„ç¼“å­˜ (ä¾›ä¸‹æ¬¡ä½¿ç”¨),
                "current_symbol": æ›´æ–°åçš„è‚¡ç¥¨ä»£ç ,
                "data_status": æ›´æ–°åçš„çŠ¶æ€,
                "missing_count": æ›´æ–°åçš„ç¼ºå¤±æ•°é‡,
                "user_guide_*": è¡¥é½æŒ‡å¼•çš„å„ä¸ªéƒ¨åˆ† (æ‰å¹³åŒ–è¾“å‡º)
            }
        """
        try:
            current_data = agent3_output
            symbol = self._extract_symbol(current_data)
            current_status = current_data.get("status", "missing_data")
            
            # åˆ¤æ–­æ˜¯å¦ç´¯ç§¯æ¨¡å¼
            is_accumulation, judgment = self._judge_accumulation_mode(
                current_data=current_data,
                cached_first_data=first_parse_data,
                cached_symbol=current_symbol,
                cached_status=data_status
            )
            
            # æ‰§è¡Œåˆå¹¶æˆ–æ–°å»º
            if is_accumulation:
                if not first_parse_data:
                    # é¦–æ¬¡ä¸Šä¼ 
                    merged_data = current_data
                    merge_history = [{
                        "round": 1,
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "fields_added": self._count_valid_fields(current_data),
                        "action": "é¦–æ¬¡è§£æ"
                    }]
                    last_merge_failed = False
                else:
                    # å¢é‡åˆå¹¶
                    first_data = json.loads(first_parse_data)
                    merged_data, merge_info = self._smart_merge(first_data, current_data)
                    
                    history = first_data.get("_merge_history", [])
                    history.append({
                        "round": len(history) + 1,
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "fields_added": merge_info["new_fields_count"],
                        "fields_updated": merge_info.get("updated_fields_count", 0),
                        "action": "å¢é‡è¡¥é½" if not merge_info.get("merge_failed") else "åˆå¹¶å¤±è´¥",
                        "failure_reason": merge_info.get("failure_reason", "")
                    })
                    merged_data["_merge_history"] = history
                    merge_history = history
                    last_merge_failed = merge_info.get("merge_failed", False)
            else:
                # æ–°ä»»åŠ¡
                merged_data = current_data
                merge_history = [{
                    "round": 1,
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "fields_added": self._count_valid_fields(current_data),
                    "action": "æ–°ä»»åŠ¡å¼€å§‹"
                }]
                last_merge_failed = False
            
            # éªŒè¯åˆå¹¶åçš„æ•°æ®
            validation_result = self._enhanced_validation(merged_data)
            
            # æ›´æ–°çŠ¶æ€
            if validation_result["is_complete"]:
                final_status = "ready"
                merged_data["status"] = "data_ready"
            else:
                final_status = "awaiting_data"
                merged_data["status"] = "missing_data"
            
            # ç”Ÿæˆè¡¥é½æŒ‡å¼•
            missing_fields = validation_result["missing_fields"]
            guide = self._generate_smart_guide(
                missing_fields=missing_fields,
                merge_history=merge_history,
                total_fields=22,
                last_merge_failed=last_merge_failed
            )
            
            # ç»„è£…ç»“æœ
            result_data = {
                **merged_data,
                "validation_summary": validation_result["summary"],
                "åˆ¤æ–­ä¾æ®": judgment,
                "_merge_history": merge_history
            }
            
            return {
                "result": json.dumps(result_data, ensure_ascii=False, indent=2),
                
                # ä¼šè¯å˜é‡æ›´æ–°
                "first_parse_data": json.dumps(merged_data, ensure_ascii=False) if final_status == "awaiting_data" else "",
                "current_symbol": symbol,
                "data_status": final_status,
                "missing_count": len(missing_fields),
                
                # è¡¥é½æŒ‡å¼• (æ‰å¹³åŒ–è¾“å‡º)
                "user_guide_summary": guide.get("summary", ""),
                "user_guide_commands": guide.get("commands_text", ""),
                "user_guide_progress": guide.get("progress", ""),
                "user_guide_priority_critical": guide.get("critical_text", ""),
                "user_guide_priority_high": guide.get("high_text", ""),
                "user_guide_priority_medium": guide.get("medium_text", ""),
                "user_guide_next_action": guide.get("next_action", ""),
                "user_guide_merge_log": guide.get("merge_log", "")
            }
        
        except Exception as e:
            import traceback
            return {
                "result": json.dumps({
                    "error": True,
                    "error_message": str(e),
                    "error_traceback": traceback.format_exc()
                }, ensure_ascii=False, indent=2),
                "first_parse_data": first_parse_data,
                "current_symbol": current_symbol,
                "data_status": "error",
                "missing_count": 0,
                "user_guide_summary": f"âš ï¸ ç³»ç»Ÿé”™è¯¯: {str(e)}",
                "user_guide_commands": "",
                "user_guide_progress": "",
                "user_guide_priority_critical": "",
                "user_guide_priority_high": "",
                "user_guide_priority_medium": "",
                "user_guide_next_action": "è¯·æ£€æŸ¥æ•°æ®åé‡è¯•",
                "user_guide_merge_log": ""
            }
    
    # ============= æ ¸å¿ƒæ–¹æ³• 1: ç´¯ç§¯æ¨¡å¼åˆ¤æ–­ =============
    
    def _judge_accumulation_mode(
        self, 
        current_data: dict,
        cached_first_data: str,
        cached_symbol: str,
        cached_status: str
    ) -> Tuple[bool, str]:
        """åˆ¤æ–­æ˜¯å¦è¿›å…¥ç´¯ç§¯æ¨¡å¼"""
        # æƒ…å†µ 1: æ— ç¼“å­˜ â†’ é¦–æ¬¡è§£æ
        if not cached_first_data or cached_status == "initial":
            return True, "é¦–æ¬¡ä¸Šä¼ ,å¼€å§‹è§£æ"
        
        # æƒ…å†µ 2: Symbol å˜åŒ– â†’ æ–°ä»»åŠ¡
        current_symbol = self._extract_symbol(current_data)
        if current_symbol != cached_symbol:
            return False, f"Symbolå˜åŒ–({cached_symbol}â†’{current_symbol}),å¼€å§‹æ–°ä»»åŠ¡"
        
        # æƒ…å†µ 3: ç¼“å­˜çŠ¶æ€ä¸º ready â†’ å·²å®Œæˆ,ä¸å†ç´¯ç§¯
        if cached_status == "ready":
            return False, "æ•°æ®å·²å®Œæ•´,å¼€å§‹æ–°ä»»åŠ¡"
        
        # æƒ…å†µ 4: ç¼“å­˜ç­‰å¾…è¡¥é½ â†’ ç´¯ç§¯æ¨¡å¼
        if cached_status == "awaiting_data":
            return True, "æ£€æµ‹åˆ°å†å²ç¼“å­˜,è¿›å…¥å¢é‡è¡¥é½æ¨¡å¼"
        
        return True, "è¿›å…¥ç´¯ç§¯æ¨¡å¼"
    
    # ============= æ ¸å¿ƒæ–¹æ³• 2: æ™ºèƒ½åˆå¹¶ =============
    
    def _smart_merge(self, first_data: dict, new_data: dict) -> Tuple[dict, dict]:
        """æ™ºèƒ½å¢é‡åˆå¹¶,é˜²æ­¢æœ‰æ•ˆæ•°æ®è¢«è¦†ç›–"""
        merged = first_data.copy()
        
        first_targets = self._get_target_dict(first_data)
        new_targets = self._get_target_dict(new_data)
        
        # æ£€æµ‹æ–°æ•°æ®æ˜¯å¦ä¸ºç©º
        new_valid_count = self._count_valid_fields_in_dict(new_targets)
        
        if new_valid_count == 0:
            print("âš ï¸ è­¦å‘Š: æ–°æ•°æ®æ— æœ‰æ•ˆå­—æ®µ,è·³è¿‡åˆå¹¶")
            return merged, {
                "new_fields_count": 0,
                "updated_fields_count": 0,
                "merge_failed": True,
                "failure_reason": "æ–°æ•°æ®æ— æœ‰æ•ˆå­—æ®µ(å¯èƒ½è§£æå¤±è´¥)"
            }
        
        new_fields_count = 0
        updated_fields_count = 0
        
        # åˆå¹¶å„ section
        for section in ["gamma_metrics", "directional_metrics", "atm_iv", "walls"]:
            if section not in first_targets:
                first_targets[section] = {}
            
            if section in new_targets:
                for key, new_value in new_targets[section].items():
                    old_value = first_targets[section].get(key)
                    
                    if self._is_valid_value(new_value):
                        if not self._is_valid_value(old_value):
                            first_targets[section][key] = new_value
                            new_fields_count += 1
                        elif old_value != new_value:
                            first_targets[section][key] = new_value
                            updated_fields_count += 1
        
        # åˆå¹¶é¡¶å±‚å­—æ®µ
        for key in ["spot_price", "em1_dollar", "symbol"]:
            old_value = first_targets.get(key)
            new_value = new_targets.get(key)
            
            if self._is_valid_value(new_value):
                if not self._is_valid_value(old_value):
                    first_targets[key] = new_value
                    new_fields_count += 1
                elif old_value != new_value:
                    first_targets[key] = new_value
                    updated_fields_count += 1
        
        # æ£€æŸ¥åˆå¹¶ç»“æœ
        if new_fields_count == 0 and updated_fields_count == 0:
            print("âš ï¸ è­¦å‘Š: åˆå¹¶æœªäº§ç”Ÿä»»ä½•å˜åŒ–")
            return merged, {
                "new_fields_count": 0,
                "updated_fields_count": 0,
                "merge_failed": True,
                "failure_reason": "æ— æ–°å¢æˆ–æ›´æ–°å­—æ®µ"
            }
        
        # åˆå¹¶ indices å’Œ technical_analysis
        if "indices" in new_data:
            if "indices" not in merged:
                merged["indices"] = {}
            for index_name in ["spx", "qqq"]:
                if index_name in new_data["indices"]:
                    if index_name not in merged["indices"]:
                        merged["indices"][index_name] = {}
                    for key, new_value in new_data["indices"][index_name].items():
                        old_value = merged["indices"][index_name].get(key)
                        if self._is_valid_value(new_value) and not self._is_valid_value(old_value):
                            merged["indices"][index_name][key] = new_value
        
        if "technical_analysis" in new_data:
            ta = new_data["technical_analysis"]
            if ta and ta.get("ta_score", 0) > 0:
                merged["technical_analysis"] = ta
        
        merged["targets"] = first_targets
        
        return merged, {
            "new_fields_count": new_fields_count,
            "updated_fields_count": updated_fields_count,
            "merge_failed": False
        }
    
    # ============= æ ¸å¿ƒæ–¹æ³• 3: å¢å¼ºéªŒè¯ =============
    
    def _enhanced_validation(self, data: dict) -> dict:
        """ä¸‰çº§éªŒè¯,åŸºäºåˆå¹¶åçš„æ•°æ®"""
        target = self._get_target_dict(data)
        
        # 22 ä¸ªå¿…éœ€å­—æ®µå®šä¹‰
        required_fields = {
            "spot_price": (target, "spot_price"),
            "em1_dollar": (target, "em1_dollar"),
            "walls.call_wall": (target.get("walls", {}), "call_wall"),
            "walls.put_wall": (target.get("walls", {}), "put_wall"),
            "walls.major_wall": (target.get("walls", {}), "major_wall"),
            "walls.major_wall_type": (target.get("walls", {}), "major_wall_type"),
            "gamma_metrics.gap_distance_dollar": (target.get("gamma_metrics", {}), "gap_distance_dollar"),
            "gamma_metrics.gap_distance_em1_multiple": (target.get("gamma_metrics", {}), "gap_distance_em1_multiple"),
            "gamma_metrics.cluster_strength_ratio": (target.get("gamma_metrics", {}), "cluster_strength_ratio"),
            "gamma_metrics.net_gex": (target.get("gamma_metrics", {}), "net_gex"),
            "gamma_metrics.net_gex_sign": (target.get("gamma_metrics", {}), "net_gex_sign"),
            "gamma_metrics.vol_trigger": (target.get("gamma_metrics", {}), "vol_trigger"),
            "gamma_metrics.spot_vs_trigger": (target.get("gamma_metrics", {}), "spot_vs_trigger"),
            "gamma_metrics.monthly_cluster_override": (target.get("gamma_metrics", {}), "monthly_cluster_override"),
            "directional_metrics.dex_same_dir_pct": (target.get("directional_metrics", {}), "dex_same_dir_pct"),
            "directional_metrics.vanna_dir": (target.get("directional_metrics", {}), "vanna_dir"),
            "directional_metrics.vanna_confidence": (target.get("directional_metrics", {}), "vanna_confidence"),
            "directional_metrics.iv_path": (target.get("directional_metrics", {}), "iv_path"),
            "directional_metrics.iv_path_confidence": (target.get("directional_metrics", {}), "iv_path_confidence"),
            "atm_iv.iv_7d": (target.get("atm_iv", {}), "iv_7d"),
            "atm_iv.iv_14d": (target.get("atm_iv", {}), "iv_14d"),
            "atm_iv.iv_source": (target.get("atm_iv", {}), "iv_source"),
        }
        
        missing_fields = []
        for field_path, (parent_dict, key) in required_fields.items():
            value = parent_dict.get(key) if isinstance(parent_dict, dict) else None
            if not self._is_valid_value(value):
                missing_fields.append({
                    "field": field_path,
                    "current_value": value
                })
        
        total_required = len(required_fields)
        provided = total_required - len(missing_fields)
        completion_rate = int((provided / total_required) * 100)
        
        return {
            "is_complete": len(missing_fields) == 0,
            "missing_fields": missing_fields,
            "summary": {
                "total_required": total_required,
                "provided": provided,
                "missing_count": len(missing_fields),
                "completion_rate": completion_rate
            }
        }
    
    # ============= æ ¸å¿ƒæ–¹æ³• 4: æ™ºèƒ½æŒ‡å¼•ç”Ÿæˆ =============
    
    def _generate_smart_guide(
        self, 
        missing_fields: list,
        merge_history: list,
        total_fields: int,
        last_merge_failed: bool = False
    ) -> dict:
        """ç”Ÿæˆæ™ºèƒ½è¡¥é½æŒ‡å¼•"""
        if not missing_fields:
            return {
                "summary": "âœ… æ•°æ®å®Œæ•´,æ— éœ€è¡¥é½",
                "commands_text": "æ— ",
                "progress": f"100% ({total_fields}/{total_fields})",
                "critical_text": "æ— ",
                "high_text": "æ— ",
                "medium_text": "æ— ",
                "next_action": "è¿›å…¥åˆ†ææµç¨‹",
                "merge_log": self._format_merge_history(merge_history)
            }
        
        provided_count = total_fields - len(missing_fields)
        progress = f"{int((provided_count/total_fields)*100)}% ({provided_count}/{total_fields})"
        
        warning = ""
        if last_merge_failed:
            warning = "\n\nâš ï¸ **è­¦å‘Š**: ä¸Šæ¬¡ä¸Šä¼ çš„æ•°æ®æœªèƒ½æˆåŠŸè¯†åˆ«,è¯·ç¡®ä¿:\n" \
                      "1. å›¾ç‰‡æ¸…æ™°å®Œæ•´\n" \
                      "2. åŒ…å«ç›®æ ‡è‚¡ç¥¨çš„æœŸæƒæ•°æ®\n" \
                      "3. å‘½ä»¤æ‰§è¡Œç»“æœå®Œæ•´æ˜¾ç¤º"
        
        # æ ¹æ®å­—æ®µè·¯å¾„ç”Ÿæˆå‘½ä»¤å»ºè®®
        commands = []
        priority_groups = {"critical": [], "high": [], "medium": []}
        
        for item in missing_fields:
            field_path = item["field"]
            cmd_info = self._suggest_command(field_path)
            
            priority = cmd_info["priority"]
            priority_groups[priority].append({
                "å­—æ®µ": field_path,
                "å‘½ä»¤": cmd_info["command"],
                "è¯´æ˜": cmd_info["description"]
            })
            
            if cmd_info["command"] not in commands:
                commands.append(cmd_info["command"])
        
        return {
            "summary": f"âŒ å½“å‰è¿›åº¦ {progress}, è¿˜éœ€è¡¥é½ {len(missing_fields)} ä¸ªå­—æ®µ{warning}",
            "commands_text": "\n".join(commands[:5]),  # æœ€å¤šæ˜¾ç¤º 5 æ¡
            "progress": progress,
            "critical_text": self._format_priority_items(priority_groups["critical"]),
            "high_text": self._format_priority_items(priority_groups["high"]),
            "medium_text": self._format_priority_items(priority_groups["medium"]),
            "next_action": f"ğŸ“‹ è¯·ç»§ç»­ä¸Šä¼ å›¾è¡¨è¡¥é½å‰©ä½™ {len(missing_fields)} ä¸ªå­—æ®µ(æ”¯æŒå¤šæ¬¡ä¸Šä¼ ç´¯ç§¯)",
            "merge_log": self._format_merge_history(merge_history)
        }
    
    # ============= è¾…åŠ©æ–¹æ³• =============
    
    def _extract_symbol(self, data: dict) -> str:
        """æå–è‚¡ç¥¨ä»£ç """
        target = self._get_target_dict(data)
        return target.get("symbol", data.get("symbol", "UNKNOWN"))
    
    def _get_target_dict(self, data: dict) -> dict:
        """æå– targets å­—å…¸"""
        targets = data.get("targets")
        
        if targets is None:
            return {}
        
        if isinstance(targets, list):
            if not targets:
                return {}
            return targets[0]
        
        if isinstance(targets, dict):
            return targets
        
        return {}
    
    def _is_valid_value(self, value: Any) -> bool:
        """åˆ¤æ–­å€¼æ˜¯å¦æœ‰æ•ˆ"""
        if value is None:
            return False
        if value == -999:
            return False
        if value in ["N/A", "æ•°æ®ä¸è¶³", "", "unknown"]:
            return False
        return True
    
    def _count_valid_fields(self, data: dict) -> int:
        """ç»Ÿè®¡æœ‰æ•ˆå­—æ®µæ•°é‡"""
        target = self._get_target_dict(data)
        count = 0
        
        for section in ["gamma_metrics", "directional_metrics", "atm_iv", "walls"]:
            if section in target and isinstance(target[section], dict):
                for value in target[section].values():
                    if self._is_valid_value(value):
                        count += 1
        
        for key in ["spot_price", "em1_dollar"]:
            if self._is_valid_value(target.get(key)):
                count += 1
        
        return count
    
    def _count_valid_fields_in_dict(self, target_dict: dict) -> int:
        """ç»Ÿè®¡å­—å…¸ä¸­çš„æœ‰æ•ˆå­—æ®µæ•°é‡"""
        count = 0
        
        for section in ["gamma_metrics", "directional_metrics", "atm_iv", "walls"]:
            if section in target_dict and isinstance(target_dict[section], dict):
                for value in target_dict[section].values():
                    if self._is_valid_value(value):
                        count += 1
        
        for key in ["spot_price", "em1_dollar"]:
            if self._is_valid_value(target_dict.get(key)):
                count += 1
        
        return count
    
    def _suggest_command(self, field_path: str) -> dict:
        """æ ¹æ®å­—æ®µè·¯å¾„å»ºè®®å‘½ä»¤"""
        command_map = {
            "gamma_metrics.vol_trigger": {
                "command": "!trigger SYMBOL 60",
                "description": "Gamma è§¦å‘çº¿",
                "priority": "critical"
            },
            "gamma_metrics.net_gex": {
                "command": "!gexn SYMBOL 60 98",
                "description": "å‡€ Gamma æ•å£",
                "priority": "critical"
            },
            "walls.call_wall": {
                "command": "!gexr SYMBOL 25 7w",
                "description": "Call å¢™ä½",
                "priority": "high"
            },
            "atm_iv.iv_7d": {
                "command": "!skew SYMBOL ivmid atm 7",
                "description": "7æ—¥ ATM æ³¢åŠ¨ç‡",
                "priority": "high"
            },
            "directional_metrics.dex_same_dir_pct": {
                "command": "!dexn SYMBOL 25 14w",
                "description": "DEX æ–¹å‘ä¸€è‡´æ€§",
                "priority": "medium"
            },
        }
        
        return command_map.get(field_path, {
            "command": "!gexr SYMBOL 25 7w",
            "description": field_path,
            "priority": "medium"
        })
    
    def _format_priority_items(self, items: list) -> str:
        """æ ¼å¼åŒ–ä¼˜å…ˆçº§åˆ—è¡¨"""
        if not items:
            return "æ— "
        
        result = []
        for i, item in enumerate(items, 1):
            result.append(
                f"{i}. **{item['å­—æ®µ']}**\n"
                f"   - å‘½ä»¤: `{item['å‘½ä»¤']}`\n"
                f"   - è¯´æ˜: {item['è¯´æ˜']}"
            )
        return "\n\n".join(result)
    
    def _format_merge_history(self, history: list) -> str:
        """æ ¼å¼åŒ–åˆå¹¶å†å²"""
        if not history:
            return "æ— å†å²è®°å½•"
        
        lines = []
        for record in history:
            lines.append(
                f"ç¬¬{record['round']}è½® ({record['timestamp']}): "
                f"{record['action']}, "
                f"æ–°å¢ {record.get('fields_added', 0)} ä¸ªå­—æ®µ"
            )
        return "\n".join(lines)