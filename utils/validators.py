"""
æ•°æ®éªŒè¯å·¥å…·ï¼ˆä¿®å¤ç‰ˆï¼‰
ä¿®å¤ï¼šæ”¯æŒå®Œæ•´è·¯å¾„ä½œä¸º cache_file å‚æ•°
"""

import re
import json
from typing import Tuple, Optional
from datetime import datetime
from pathlib import Path


def validate_symbol(symbol: str) -> Tuple[bool, str]:
    """éªŒè¯è‚¡ç¥¨ä»£ç """
    if not symbol:
        return False, "è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º"
    
    symbol = symbol.strip().upper()
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºä¿ç•™å…³é”®å­—
    reserved_keywords = ["UNKNOWN", "TEST", "N/A", "NULL", "NONE", "ERROR"]
    if symbol in reserved_keywords:
        return False, f"'{symbol}' æ˜¯ä¿ç•™å…³é”®å­—ï¼Œä¸èƒ½ä½œä¸ºè‚¡ç¥¨ä»£ç "
    
    # æ£€æŸ¥é•¿åº¦ï¼ˆ1-10ä¸ªå­—ç¬¦ï¼‰
    if len(symbol) < 1 or len(symbol) > 10:
        return False, f"è‚¡ç¥¨ä»£ç é•¿åº¦å¿…é¡»åœ¨ 1-10 ä¹‹é—´ï¼Œå½“å‰: {len(symbol)}"
    
    # æ£€æŸ¥å­—ç¬¦ï¼ˆä»…å…è®¸å­—æ¯ã€æ•°å­—ã€ç‚¹å·ã€çŸ­æ¨ªçº¿ï¼‰
    if not re.match(r'^[A-Z0-9\.\-]+$', symbol):
        return False, f"è‚¡ç¥¨ä»£ç åªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€ç‚¹å·å’ŒçŸ­æ¨ªçº¿"
    
    # æ£€æŸ¥æ˜¯å¦ä»¥æ•°å­—å¼€å¤´ï¼ˆé€šå¸¸æ— æ•ˆï¼‰
    if symbol[0].isdigit():
        return False, f"è‚¡ç¥¨ä»£ç ä¸èƒ½ä»¥æ•°å­—å¼€å¤´"
    
    return True, symbol


def normalize_symbol(symbol: str) -> str:
    """æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼ˆæ— éªŒè¯ç‰ˆæœ¬ï¼‰"""
    if not symbol:
        return "UNKNOWN"
    
    return symbol.strip().upper()


def validate_cache_file(cache_file: str, symbol: str) -> tuple[bool, str, dict]:
    """
    éªŒè¯ç¼“å­˜æ–‡ä»¶çš„åˆæ³•æ€§ï¼ˆæ”¯æŒè·¯å¾„è¾“å…¥ï¼‰
    
    Args:
        cache_file: ç¼“å­˜æ–‡ä»¶åæˆ–è·¯å¾„
            æ”¯æŒæ ¼å¼ï¼š
            - æ–‡ä»¶åï¼šNVDA_o_20251201.json æˆ– NVDA_o_20251201
            - ç›¸å¯¹è·¯å¾„ï¼š./data/output/NVDA/20251201/NVDA_o_20251201.json
            - ç»å¯¹è·¯å¾„ï¼š/path/to/NVDA_o_20251201.json
        symbol: è‚¡ç¥¨ä»£ç 
        
    Returns:
        (is_valid, error_message, cache_info)
    """
    # ä¿®å¤ï¼šæå–æ–‡ä»¶åï¼ˆå…¼å®¹è·¯å¾„è¾“å…¥ï¼‰
    cache_path = Path(cache_file)
    filename = cache_path.name
    
    # [Fix] è‡ªåŠ¨è¡¥å…¨ .json åç¼€
    if not filename.endswith('.json'):
        filename = f"{filename}.json"
        cache_path = cache_path.parent / filename if cache_path.parent != Path('.') else Path(filename)
    
    # 1. è§£ææ–‡ä»¶å
    match = re.match(r'(\w+)_o_(\d{8})\.json', filename)
    if not match:
        return False, f"ç¼“å­˜æ–‡ä»¶åæ ¼å¼é”™è¯¯ï¼Œåº”ä¸º {{SYMBOL}}_o_{{YYYYMMDD}}.json", {}
    
    file_symbol = match.group(1)
    file_date = match.group(2)
    
    # 2. éªŒè¯è‚¡ç¥¨ä»£ç åŒ¹é…
    if file_symbol.upper() != symbol.upper():
        return False, f"ç¼“å­˜æ–‡ä»¶è‚¡ç¥¨ä»£ç  ({file_symbol}) ä¸å‚æ•°ä¸åŒ¹é… ({symbol})", {}
    
    # 3. éªŒè¯æ—¥æœŸæ ¼å¼
    try:
        parsed_date = datetime.strptime(file_date, "%Y%m%d")
    except ValueError:
        return False, f"ç¼“å­˜æ–‡ä»¶æ—¥æœŸæ ¼å¼é”™è¯¯: {file_date}", {}
    
    # 4. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è·¯å¾„ï¼‰
    if cache_path.exists():
        final_cache_path = cache_path
    else:
        # å›é€€åˆ°æ ‡å‡†è·¯å¾„
        final_cache_path = Path(f"data/output/{symbol}/{file_date}/{filename}")
        if not final_cache_path.exists():
            return False, f"ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {final_cache_path}", {}
    
    # 5. åŠ è½½å¹¶éªŒè¯æ–‡ä»¶å†…å®¹
    try:
        with open(final_cache_path, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)
    except Exception as e:
        return False, f"ç¼“å­˜æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}", {}
    
    # 6. éªŒè¯å†…éƒ¨æ—¥æœŸä¸€è‡´æ€§
    start_date = cache_data.get("start_date", "")
    if start_date:
        internal_date = start_date.replace("-", "")
        if internal_date != file_date:
            return False, (
                f"ç¼“å­˜æ–‡ä»¶å†…éƒ¨æ—¥æœŸä¸åŒ¹é…ï¼\n"
                f"  æ–‡ä»¶åæ—¥æœŸ: {file_date}\n"
                f"  å†…éƒ¨æ—¥æœŸ: {internal_date} ({start_date})"
            ), {}
    
    cache_info = {
        "symbol": file_symbol,
        "date": file_date,
        "parsed_date": parsed_date,
        "cache_path": final_cache_path,  # è¿”å›å®é™…è·¯å¾„
        "start_date": start_date,
        "has_source_target": cache_data.get("source_target") is not None,
        "snapshot_count": sum(1 for k in cache_data.keys() if k.startswith("snapshots_"))
    }
    
    return True, "", cache_info


def resolve_input_file_path(input_arg: str, symbol: str = None) -> Tuple[Optional[Path], str]:
    """
    æ™ºèƒ½è§£æè¾“å…¥æ–‡ä»¶è·¯å¾„
    
    æ”¯æŒçš„è¾“å…¥æ ¼å¼ï¼š
    1. å®Œæ•´è·¯å¾„: data/input/INTC_i_20250103.json
    2. ç›¸å¯¹è·¯å¾„: INTC_i_20250103.json
    3. æ— åç¼€: INTC_i_20250103
    4. æ¨¡ç³ŠåŒ¹é…: symbol_i_datetime (è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°)
    
    Args:
        input_arg: ç”¨æˆ·è¾“å…¥çš„æ–‡ä»¶è·¯å¾„/åç§°
        symbol: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ¨¡ç³ŠåŒ¹é…ï¼‰
        
    Returns:
        (resolved_path, error_message)
    """
    from loguru import logger
    
    # 1. æ¸…ç†è¾“å…¥
    input_str = str(input_arg).strip()
    
    # 2. å¦‚æœæ˜¯å®Œæ•´è·¯å¾„ä¸”å­˜åœ¨ï¼Œç›´æ¥è¿”å›
    input_path = Path(input_str)
    if input_path.exists() and input_path.is_file():
        logger.debug(f"âœ… ä½¿ç”¨å®Œæ•´è·¯å¾„: {input_path}")
        return input_path, None
    
    # 3. å°è¯•æ·»åŠ  data/input/ å‰ç¼€
    if not input_str.startswith("data/input/"):
        input_str_with_prefix = f"data/input/{input_str}"
        
        # 3.1 å°è¯•ç›´æ¥è·¯å¾„
        candidate = Path(input_str_with_prefix)
        if candidate.exists() and candidate.is_file():
            logger.debug(f"âœ… è¡¥å…¨è·¯å¾„: {candidate}")
            return candidate, None
        
        # 3.2 å°è¯•æ·»åŠ  .json åç¼€
        if not input_str.endswith('.json'):
            candidate_with_ext = Path(f"{input_str_with_prefix}.json")
            if candidate_with_ext.exists() and candidate_with_ext.is_file():
                logger.debug(f"âœ… è¡¥å…¨è·¯å¾„+åç¼€: {candidate_with_ext}")
                return candidate_with_ext, None
    
    # 4. å¦‚æœæœ‰ symbolï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆæŸ¥æ‰¾æœ€æ–°æ–‡ä»¶ï¼‰
    if symbol:
        input_dir = Path("data/input")
        if input_dir.exists():
            # æ„å»ºåŒ¹é…æ¨¡å¼
            # æ”¯æŒ: symbol_i_* æˆ– *_i_* æ ¼å¼
            pattern = f"{symbol.upper()}_i_*.json"
            
            matching_files = sorted(
                input_dir.glob(pattern),
                key=lambda p: p.stat().st_mtime,
                reverse=True
            )
            
            if matching_files:
                latest_file = matching_files[0]
                logger.info(f"ğŸ“‚ è‡ªåŠ¨åŒ¹é…åˆ°æœ€æ–°æ–‡ä»¶: {latest_file.name}")
                return latest_file, None
    
    # 5. æ‰€æœ‰å°è¯•å¤±è´¥
    error_msg = f"æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶: {input_arg}"
    
    # æä¾›å¯èƒ½çš„æ–‡ä»¶åˆ—è¡¨
    input_dir = Path("data/input")
    if input_dir.exists():
        available = [f.name for f in input_dir.glob("*.json")][:5]
        if available:
            error_msg += f"\nğŸ’¡ data/input/ ç›®å½•ä¸‹çš„æ–‡ä»¶:\n   - " + "\n   - ".join(available)
    
    return None, error_msg